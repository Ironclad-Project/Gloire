#! /bin/sh

# Copyright (C) 2022-2025 mintsuki

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

set -e

IFS=" ""	"'
'

LC_COLLATE=C
export LC_COLLATE

umask 0022

jinx_major_ver="0.4"
jinx_minor_ver="10"

jinx_version="${jinx_major_ver}.${jinx_minor_ver}"

die() {
    echo "$1"
    exit 1
}

case "$1" in
    version|--version)
        echo "Jinx version $jinx_version"
        exit 0
        ;;
esac

if ! [ "$(uname -s)" = "Linux" ]; then
    die "$0: Jinx only supports running on Linux hosts."
fi

if [ "$(id -u)" = "0" ]; then
    die "$0: Jinx does not support running as root."
fi

debian_snapshot="20250401T023134Z"

case "$(uname -m)" in
    x86_64)
        debian_architecture=amd64
        debian_rootfs_b2sum=8153d1895cb9530f469eadab418a9105fd2cdbb93ceaedcfb01e7819ff64a9cff3ee2221b6b7412ba39230338ac2eb012e918fbc5f28662c3913f861b1f6aaa0
        ;;
    aarch64)
        debian_architecture=arm64
        debian_rootfs_b2sum=07d554637d5492652ed997a07ded2cfc3827e534d07c3a73397817e97ec15a2aa53f8117ba69e572e5519ff8dc9ab3a0a3313d26eeb3197d81247826735020d2
        ;;
    arm*)
        debian_architecture=armhf
        debian_rootfs_b2sum=43d08d9119bea19c5de13c33153a371f579a0ebc4c416c06f3df79ccfdb1b037a5d4796144a5bab04a09e59c2c45eb27c0f7a722a7a8c7c5e6d43e4b6e9533ba
        ;;
    i?86)
        debian_architecture=i386
        debian_rootfs_b2sum=6383a7683c354a50a8d29a740b75af027332649b64c9e5d75fcc7c0136ab1dfae59f0cb0162f5c9e7ba16c9013ea5e42a6f56ca198d39f4ca0e4d75e8a51bc35
        ;;
    mips64el)
        debian_architecture=mips64el
        debian_rootfs_b2sum=b7dde57d789ed66160307aff45a5a0569db4185100314a6c44e26f3aaaaab80794c93e663dfe9dd34091c9daa1b5387d6e458e1a5b6d75b25385ed46e4d66aaf
        ;;
    ppc64le)
        debian_architecture=ppc64el
        debian_rootfs_b2sum=9ed1f8ca4d0a4f70cf49455a59f969d8f1b65588a0fb40d35d9469066f30c5de9cd4a6278fc5394f5388e9f71d9d5f8fdcdfc77553a540955099d155c17e16f6
        ;;
    riscv64)
        debian_architecture=riscv64
        debian_rootfs_b2sum=50c5a6a6df49e6501309225f17cdbfb3078109a042b2c97289537e33ae1853dff95d75c02bcf77509af21aad11098300834ffe2642449091ef228c5cc8fdad04
        ;;
    s390x)
        debian_architecture=s390x
        debian_rootfs_b2sum=334b2bf1a9ab6009236185055c1bf5e6972bdd7751b1269419fdbc0c2e75adec24bc7ef173478157faee53b6d67bbdf9b65ddbfda55b207a7accfbee60b1fd0d
        ;;
    *)
        die "$0: Unsupported architecture: $(uname -m)"
        ;;
esac

XSTOW_VERSION=1.1.1

make_dir() {
    for d in "$@"; do
        mkdir -p "$d"
        dn="$(cd "$d" && pwd -P)"
        while true; do
            if [ "$dn" = "$base_dir" ] || [ "$dn" = "$build_dir" ] || [ "$dn" = "/" ]; then
                break
            fi
            chmod 755 "$dn"
            dn="$(dirname "$dn")"
        done
    done
}

script_name="$(basename "$0")"
script_dir="$(dirname "$0")"
if [ "$script_dir" = "." ] || [ -z "$script_dir" ]; then
    if echo "$0" | grep "/" >/dev/null 2>&1; then
        script_dir=.
    else
        script_dir="$(dirname $(which "${script_name}"))"
    fi
fi
script_dir="$(cd "${script_dir}" && pwd -P)"
script="${script_dir}/${script_name}"

in_container=false
if [ "$script" = "//jinx" ]; then
    in_container=true
fi

if [ "$in_container" = "false" ] && [ -f ./jinx-parameters ]; then
    . ./jinx-parameters
fi

if [ -z "$JINX_PARALLELISM" ]; then
    max_threads_by_mem="$(( ((($(free | awk '/^Mem:/{print $2}') + 1048575) / 1048576) + 1) / 2 ))"
    parallelism="$(nproc 2>/dev/null || echo 1)"
    parallelism="$(( $parallelism < $max_threads_by_mem ? $parallelism : $max_threads_by_mem ))"
else
    parallelism="$JINX_PARALLELISM"
fi

build_dir="$(pwd -P)"

if [ -z "$JINX_SOURCE_DIR" ]; then
    base_dir="$build_dir"
else
    base_dir="$(cd "$JINX_SOURCE_DIR" && pwd -P)"
fi

if [ -z "$JINX_CONFIG_FILE" ]; then
    JINX_CONFIG_FILE="${base_dir}/jinx-config"
fi
if ! [ -d "$(dirname "$JINX_CONFIG_FILE")" ]; then
    die "$0: cannot access config file directory"
fi
JINX_CONFIG_FILE="$(cd "$(dirname "$JINX_CONFIG_FILE")" && pwd -P)"/"$(basename "$JINX_CONFIG_FILE")"

if [ -z "$JINX_CACHE_DIR" ]; then
    JINX_CACHE_DIR="${base_dir}/.jinx-cache"
fi
if ! [ -d "$(dirname "$JINX_CACHE_DIR")" ]; then
    die "$0: cannot access cache directory parent"
fi
make_dir "$JINX_CACHE_DIR"
JINX_CACHE_DIR="$(cd "$JINX_CACHE_DIR" && pwd -P)"

if [ "$in_container" = "false" ]; then
    make_dir "${base_dir}/sources" "${build_dir}/host-builds" "${build_dir}/host-pkgs" "${build_dir}/builds" "${build_dir}/pkgs"
fi

apt_cache="$JINX_CACHE_DIR/apt-cache"

temp_collect=""
trap 'eval rm -rf "$temp_collect"' EXIT

make_temp() {
    tmp="$(mktemp "$JINX_CACHE_DIR/tmp.XXXXXXXX")"
    temp_collect="${temp_collect} \"${tmp}\""
    if [ "$1" = "-d" ]; then
        rm -f "${tmp}"
        make_dir "${tmp}"
    fi
}

build_hostdeps() {
    for hostdep in ${hostdeps} ${hostrundeps}; do
        [ -f "${base_dir}"/host-recipes/${hostdep} ] || die "missing host dependency '${hostdep}' for recipe '${name}'"

        [ -d "${build_dir}"/host-pkgs/${hostdep} ] && continue

        "${script}" host-build ${hostdep}
    done
}

build_deps() {
    for dep in ${deps} ${builddeps}; do
        [ -f "${base_dir}"/recipes/${dep} ] || die "missing dependency '${dep}' for recipe '${name}'"

        [ -d "${build_dir}"/pkgs/${dep} ] && continue

        "${script}" build ${dep}
    done
}

get_hostdeps_file_run() {
    deps_to_do=""

    for hostdep in ${hostrundeps}; do
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${hostdep}"
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || printf " ${hostdep} " >> "${hostdeps_file}"
    done

    for hostdep in ${deps_to_do}; do
        "${script}" internal-get-hostdeps-file-run ${hostdep} "${hostdeps_file}"
    done
}

get_hostdeps_file() {
    deps_to_do=""

    for hostdep in ${hostdeps} ${hostrundeps}; do
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${hostdep}"
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || printf " ${hostdep} " >> "${hostdeps_file}"
    done

    for hostdep in ${deps_to_do}; do
        "${script}" internal-get-hostdeps-file-run ${hostdep} "${hostdeps_file}"
    done
}

get_builddeps_file() {
    deps_to_do=""

    for dep in ${deps} ${builddeps}; do
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${dep}"
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || printf " ${dep} " >> "${deps_file}"
    done

    for dep in ${deps_to_do}; do
        "${script}" internal-get-deps-file ${dep} "${deps_file}"
    done
}

get_deps_file() {
    deps_to_do=""

    for dep in ${deps}; do
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${dep}"
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || printf " ${dep} " >> "${deps_file}"
    done

    for dep in ${deps_to_do}; do
        "${script}" internal-get-deps-file ${dep} "${deps_file}"
    done
}

run_in_container1() {
    if ! [ -z "$TERM" ]; then
        run_in_cont1_term="--env TERM=\"$TERM\""
    fi

    if ! [ -z "$COLORTERM" ]; then
        run_in_cont1_colorterm="--env COLORTERM=\"$COLORTERM\""
    fi

    run_in_cont1_root="$1"
    shift 1

    "$JINX_CACHE_DIR/rbrt" \
        --root "$run_in_cont1_root" rw \
        --uid 0 \
        --gid 0 \
        --env HOME=/root \
        --env LANG=en_US.UTF-8 \
        --env LC_COLLATE=C \
        --env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin \
        --env LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib:/usr/lib64:/usr/lib \
        ${run_in_cont1_term} \
        ${run_in_cont1_colorterm} \
        -m"${apt_cache}":/var/cache/apt/archives \
        -- \
        "$@"
}

check_duplicates() {
    for elem in $(cd "$1" && find .); do
        if [ -f "$2"/${elem} ] || [ -L "$2"/${elem} ]; then
            return 1
        fi
    done
}

prepare_container() {
    cd "${build_dir}"

    make_temp
    hostdeps_file="${tmp}"
    make_temp
    deps_file="${tmp}"

    build_hostdeps
    build_deps

    get_hostdeps_file
    get_builddeps_file

    make_temp -d
    container_pkgs="${tmp}"
    make_temp -d
    sysroot_dir="${tmp}"

    rm -rf "$JINX_CACHE_DIR"/saved-info-dir
    for dep in $(cat "${deps_file}"); do
        if [ -f "${build_dir}"/pkgs/${dep}/usr/share/info/dir ]; then
            mv "${build_dir}"/pkgs/${dep}/usr/share/info/dir "$JINX_CACHE_DIR"/saved-info-dir
        fi
        copy_failed=0
        check_duplicates "${build_dir}"/pkgs/${dep} "${sysroot_dir}" || copy_failed=1
        cp -Pplr "${build_dir}"/pkgs/${dep}/. "${sysroot_dir}"/
        if [ -f "$JINX_CACHE_DIR"/saved-info-dir ]; then
            mv "$JINX_CACHE_DIR"/saved-info-dir "${build_dir}"/pkgs/${dep}/usr/share/info/dir
        fi
        if [ "$copy_failed" = 1 ]; then
            die "jinx: error: Dependency '${dep}' contains file confilcts"
        fi
    done

    if [ "$JINX_NATIVE_MODE" = "yes" ] && [ -z "$cross_compile" ]; then
        imgroot="${sysroot_dir}"
    else
        for hostdep in $(cat "${hostdeps_file}"); do
            if [ -f "${build_dir}"/host-pkgs/${hostdep}/usr/local/share/info/dir ]; then
                mv "${build_dir}"/host-pkgs/${hostdep}/usr/local/share/info/dir "$JINX_CACHE_DIR"/saved-info-dir
            fi
            copy_failed=0
            check_duplicates "${build_dir}"/host-pkgs/${hostdep}/usr/local "${container_pkgs}" || copy_failed=1
            cp -Pplr "${build_dir}"/host-pkgs/${hostdep}/usr/local/. "${container_pkgs}"/
            if [ -f "$JINX_CACHE_DIR"/saved-info-dir ]; then
                mv "$JINX_CACHE_DIR"/saved-info-dir "${build_dir}"/host-pkgs/${hostdep}/usr/local/share/info/dir
            fi
            if [ "$copy_failed" = 1 ]; then
                die "jinx: error: Dependency '${hostdep}' contains file confilcts"
            fi
        done

        imagedeps="$(echo "${imagedeps}" | xargs -n1 | sort -u | xargs)"

        pkgset=""
        for pkg in ${imagedeps}; do
            pkgset="${pkgset}${pkg}/"

            if [ -f "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid" ]; then
                continue
            fi

            make_dir "$JINX_CACHE_DIR/sets/${pkgset}"

            cp -Pplrf "$JINX_CACHE_DIR/sets/${pkgset}../.image" "$JINX_CACHE_DIR/sets/${pkgset}.image"

            rm -f "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid"

            if ! run_in_container1 "$JINX_CACHE_DIR/sets/${pkgset}.image" apt-get install -y "${pkg}"; then
                die 'Jinx error: Installing an imagedep failed.'
            fi

            # Fix permissions of files
            for f in $(find "$JINX_CACHE_DIR/sets/${pkgset}.image" -perm 000 2>/dev/null); do
                chmod 755 "$f"
            done

            touch "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid"
        done

        imgroot="$JINX_CACHE_DIR/sets/${pkgset}.image"
    fi
}

run_in_container() {
    if [ "${allow_network}" = "yes" ]; then
        unshare_net_flag=""
    else
        unshare_net_flag="-n"
    fi

    if [ ! -z "$TERM" ]; then
        run_in_cont_term="--env TERM=\"$TERM\""
    fi

    if ! [ -z "$COLORTERM" ]; then
        run_in_cont_colorterm="--env COLORTERM=\"$COLORTERM\""
    fi

    touch "${imgroot}/jinx"
    chmod +x "${imgroot}/jinx"
    touch "${imgroot}/jinx-config"
    make_dir "${imgroot}/base_dir" "${imgroot}/sources" "${imgroot}/build_dir"

    native_mode_mounts=""
    if ( [ "$JINX_NATIVE_MODE" = "yes" ] && [ "$cross_compile" = "yes" ] ) || ( ! [ "$JINX_NATIVE_MODE" = "yes" ] ); then
        make_dir "${imgroot}/sysroot"

        container_pkgs_native_mount="-m${container_pkgs}:/usr/local:ro"
        sysroot_native_mount="-m${sysroot_dir}:/sysroot:ro"

        run_in_cont_lang=en_US.UTF-8
    else
        if ! [ -z "$JINX_NATIVE_LANG" ]; then
            run_in_cont_lang="$JINX_NATIVE_LANG"
        else
            run_in_cont_lang=C
        fi
    fi

    run_in_cont_argvar=""
    for arg in "$@"; do
        run_in_cont_argvar="$run_in_cont_argvar \"$arg\""
    done

    shadow_git_dir_build=""
    if [ -d "${build_dir}"/.git ]; then
        make_temp -d
        shadow_git_dir_build="-m${tmp}:/build_dir/.git"
    fi

    shadow_git_dir_base=""
    if [ -d "${base_dir}"/.git ]; then
        make_temp -d
        shadow_git_dir_base="-m${tmp}:/base_dir/.git"
    fi

    "$JINX_CACHE_DIR/rbrt" \
        --root "${imgroot}" \
        --uid $(id -u) \
        --gid $(id -g) \
        --env HOME=/root \
        --env LANG=${run_in_cont_lang} \
        --env LC_COLLATE=C \
        --env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin \
        --env LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib:/usr/lib64:/usr/lib \
        ${run_in_cont_term} \
        ${run_in_cont_colorterm} \
        --env JINX_PARALLELISM="$parallelism" \
        --env JINX_CONFIG_FILE=/jinx-config \
        --env JINX_SOURCE_DIR=/base_dir \
        ${container_pkgs_native_mount:+"${container_pkgs_native_mount}"} \
        ${sysroot_native_mount:+"${sysroot_native_mount}"} \
        -m"${script}":/jinx:ro \
        -m"${JINX_CONFIG_FILE}":/jinx-config:ro \
        -m"${base_dir}":/base_dir${container_base_dir_ro} \
        ${shadow_git_dir_base:+"${shadow_git_dir_base}"} \
        -m"${base_dir}"/sources:/base_dir/sources${container_sources_ro} \
        -m"${build_dir}":/build_dir \
        ${shadow_git_dir_build:+"${shadow_git_dir_build}"} \
        ${unshare_net_flag} \
        --workdir / \
        -- \
        /bin/bash -c "cd /build_dir && /bin/bash /jinx $run_in_cont_argvar"

    rm -rf "${imgroot}/sysroot" "${imgroot}/jinx" "${imgroot}/jinx-config" "${imgroot}/base_dir" "${imgroot}/sources" "${imgroot}/build_dir"
}

destroy_container() {
    rm -rf "${container_pkgs}" "${sysroot_dir}"
}

do_hg_fetch() {
    [ -d "${source_dir}" ] && return
    hg clone "${hg_url}" "${base_dir}"/sources/${name}
    ( cd "${base_dir}"/sources/${name} && hg up "${tag}" )
}

do_git_fetch() {
    [ -d "${source_dir}" ] && return
    if ! [ -z "${commit}" ]; then
        git clone "${git_url}" "${base_dir}"/sources/${name}
        ( cd "${base_dir}"/sources/${name} && git checkout ${commit} )
    elif [ "${shallow}" = "no" ]; then
        git clone "${git_url}" --branch="${branch}" "${base_dir}"/sources/${name}
    else
        git clone "${git_url}" --branch="${branch}" --depth=1 "${base_dir}"/sources/${name}
    fi
}

do_tarball_fetch() {
    [ -d "${source_dir}" ] && return

    tarball_path="${base_dir}"/sources/"$(basename "${tarball_url}")"

    if ! [ -f "$tarball_path" ]; then
        make_temp
        download_path="${tmp}"

        curl -L -o "${download_path}" "${tarball_url}"
        mv "${download_path}" "${tarball_path}"
    fi

    checksum_verified=no

    if ! [ -z "${tarball_sha256}" ]; then
        actual_sha256="$(sha256sum "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_sha256} = ${tarball_sha256} ]; then
            die "* error: Failed to verify SHA256 for ${name}.
  Expected '${tarball_sha256}';
  got '${actual_sha256}'."
        fi
        checksum_verified=yes
    fi
    if ! [ -z "${tarball_sha512}" ]; then
        actual_sha512="$(sha512sum "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_sha512} = ${tarball_sha512} ]; then
            die "* error: Failed to verify SHA512 for ${name}.
  Expected '${tarball_sha512}';
  got '${actual_sha512}'."
        fi
        checksum_verified=yes
    fi
    if ! [ -z "${tarball_blake2b}" ]; then
        actual_blake2b="$("$JINX_CACHE_DIR/b2sum" "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_blake2b} = ${tarball_blake2b} ]; then
            die "* error: Failed to verify BLAKE2B for ${name}.
  Expected '${tarball_blake2b}';
  got '${actual_blake2b}'."
        fi
        checksum_verified=yes
    fi

    if [ "${checksum_verified}" = "no" ]; then
        die "* error: No checksum method specified for ${name}"
    fi

    make_temp -d
    extract_dir="${tmp}"

    ( cd "${extract_dir}" && tar -xf "${tarball_path}" )

    mv "${extract_dir}"/* "${base_dir}"/sources/${name} >/dev/null 2>&1 || (
        make_dir "${base_dir}"/sources/${name}
        mv "${extract_dir}"/* "${base_dir}"/sources/${name}/
    )

    rm -rf "${extract_dir}" "${tarball_path}"
}

get_real_source_dir() {
    if [ -z "${source_dir}" ]; then
        source_dir="${base_dir}"/sources/${name}
    else
        source_dir="${base_dir}"/"${source_dir}"
        is_local_package=true
    fi
}

do_fetch() {
    make_dir "${base_dir}"/sources

    if ! [ -z "${git_url}" ]; then
        do_git_fetch
    elif ! [ -z "${hg_url}" ]; then
        do_hg_fetch
    elif ! [ -z "${tarball_url}" ]; then
        do_tarball_fetch
    fi
}

default_recipe_steps() {
    prepare() {
        true
    }

    configure() {
        true
    }

    build() {
        true
    }

    package() {
        true
    }
}

source_source_recipe() {
    if [ -f "${base_dir}"/source-recipes/$1 ]; then
        . "${base_dir}"/source-recipes/$1
    elif [ -f "${base_dir}"/recipes/$1 ]; then
        . "${base_dir}"/recipes/$1

        unset deps
        unset builddeps
        unset hostrundeps
        imagedeps="${source_imagedeps}"
        hostdeps="${source_hostdeps}"
        deps="${source_deps}"
        allow_network="${source_allow_network}"
    else
        die "* could not find source recipe '$1'"
    fi
}

cont_patch() {
    source_source_recipe $1

    get_real_source_dir

    make_temp
    patch_trash="${tmp}"

    cd "${source_dir}"

    if [ -d "${base_dir}"/patches/${name} ]; then
        for patch in "${base_dir}"/patches/${name}/*; do
            [ "${patch}" = "${base_dir}/patches/${name}/*" ] && break
            [ "${patch}" = "${base_dir}"/patches/${name}/jinx-working-patch.patch ] && continue
            patch --no-backup-if-mismatch -p1 -r "${patch_trash}" < "${patch}"
        done
    fi

    cp -rp "${source_dir}" "${base_dir}"/sources/${name}-clean

    if [ -f "${base_dir}"/patches/${name}/jinx-working-patch.patch ]; then
        patch --no-backup-if-mismatch -p1 -r "${patch_trash}" < "${base_dir}"/patches/${name}/jinx-working-patch.patch
    fi

    cp -rp "${source_dir}" "${base_dir}"/sources/${name}-workdir

    cd "${base_dir}"

    touch "${base_dir}"/sources/${name}.patched
}

do_prepare() {
    default_recipe_steps

    source_source_recipe $1

    get_real_source_dir

    [ -f "${base_dir}"/sources/${name}.prepared ] && return

    sysroot_dir="/sysroot"

    cd "${source_dir}"
    [ "${is_local_package}" = true ] || container_base_dir_ro=":ro"
    prepare
    container_base_dir_ro=""
    cd "${base_dir}"

    touch "${base_dir}"/sources/${name}.prepared
}

do_configure_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    make_dir "${build_dir}"/host-builds/${name}

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/host-builds/${name}
    configure
    cd "${base_dir}"
}

do_build_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    make_dir "${build_dir}"/host-builds/${name}

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/host-builds/${name}
    build
    cd "${base_dir}"
}

do_package_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    dest_dir="${build_dir}"/host-pkgs/${name}

    rm -rf "${dest_dir}"
    make_dir "${dest_dir}"

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    make_dir "${dest_dir}${prefix}"

    cd "${build_dir}"/host-builds/${name}
    package
    cd "${base_dir}"

    # Remove libtool files
    for i in $(find "${dest_dir}${prefix}" -name "*.la"); do
        rm -rvf $i
    done
}

do_configure() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    make_dir "${build_dir}"/builds/${name}

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/builds/${name}
    configure
    cd "${base_dir}"
}

do_build() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    make_dir "${build_dir}"/builds/${name}

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/builds/${name}
    build
    cd "${base_dir}"
}

do_package() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    dest_dir="${build_dir}"/pkgs/${name}

    rm -rf "${dest_dir}"
    make_dir "${dest_dir}"

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    make_dir "${dest_dir}${prefix}"

    cd "${build_dir}"/builds/${name}
    package
    cd "${base_dir}"

    # Remove libtool files
    for i in $(find "${dest_dir}${prefix}" -name "*.la"); do
        rm -rvf $i
    done
}

precont_patch() {
    [ -f "${base_dir}"/sources/$1.patched ] && return

    cross_compile=yes
    prepare_container
    run_in_container internal-cont-patch $1
    destroy_container
}

do_source() {
    source_source_recipe $1

    get_real_source_dir

    do_fetch

    "${script}" internal-precont-patch $1

    [ -f "${base_dir}"/sources/$1.prepared ] && return

    cross_compile=yes
    prepare_container
    run_in_container internal-prepare $1
    destroy_container
}

do_cmd_rebuild() {
    rm -rf "${build_dir}"/builds/"$1"

    do_pkg "$1"
}

do_cmd_host_rebuild() {
    rm -rf "${build_dir}"/host-builds/"$1"

    do_host_pkg "$1"
}

do_cmd_prepare() {
    source_source_recipe $1

    [ -f "${base_dir}"/sources/$1.patched ] || die "cannot regenerate non-built package"

    get_real_source_dir

    make_temp
    patch_file="${tmp}"

    if ! [ "${is_local_package}" = true ]; then
        cd "${base_dir}"/sources

        # exclude version control dirs
        make_temp -d
        vc_dir_clean="${tmp}"
        rm -rf "${vc_dir_clean}"
        make_temp -d
        vc_dir_workdir="${tmp}"
        rm -rf "${vc_dir_workdir}"

        if ! [ -z "${git_url}" ]; then
            mv $1-clean/.git "${vc_dir_clean}"
            mv $1-workdir/.git "${vc_dir_workdir}"
        elif ! [ -z "${hg_url}" ]; then
            mv $1-clean/.hg "${vc_dir_clean}"
            mv $1-workdir/.hg "${vc_dir_workdir}"
        fi

        git diff --no-index --no-prefix $1-clean $1-workdir >"${patch_file}" || true

        if ! [ -z "${git_url}" ]; then
            mv "${vc_dir_clean}" $1-clean/.git
            mv "${vc_dir_workdir}" $1-workdir/.git
        elif ! [ -z "${hg_url}" ]; then
            mv "${vc_dir_clean}" $1-clean/.hg
            mv "${vc_dir_workdir}" $1-workdir/.hg
        fi

        if [ -s "${patch_file}" ]; then
            make_dir "${base_dir}"/patches/$1
            mv "${patch_file}" "${base_dir}"/patches/$1/jinx-working-patch.patch
        fi

        cd "${base_dir}"

        rm -rf "${source_dir}"
        cp -rp "${base_dir}"/sources/$1-workdir "${source_dir}"
    fi

    rm -rf "${base_dir}"/sources/$1.prepared

    cross_compile=yes
    prepare_container
    run_in_container internal-prepare $1
    destroy_container
}

do_host_pkg() {
    unset from_source
    . "${base_dir}"/host-recipes/$1

    echo "* building host package: $name"

    if ! [ -z "${from_source}" ]; then
        from_source="$(. "${base_dir}"/host-recipes/$1 && echo "$from_source")"
        [ -f "${base_dir}"/sources/${from_source}.prepared ] || \
            "${script}" internal-source "${from_source}"
    fi

    cross_compile=yes
    prepare_container

    if ! [ "${allow_source_writes}" = "yes" ]; then
        container_sources_ro=":ro"
    fi

    if ! [ -d "${base_dir}"/host-builds/$1 ]; then
        run_in_container internal-configure-host $1
    fi
    run_in_container internal-build-host $1
    rm -rf "${base_dir}"/host-pkgs/$1
    if ! run_in_container internal-package-host $1; then
        rm -rf "${base_dir}"/host-pkgs/$1
        return 1
    fi
    unset container_sources_ro

    destroy_container
}

do_pkg() {
    unset from_source
    . "${base_dir}"/recipes/$1

    echo "* building package: $name"

    if ! [ -z "${from_source}" ]; then
        from_source="$(. "${base_dir}"/recipes/$1 && echo "$from_source")"
        [ -f "${base_dir}"/sources/${from_source}.prepared ] || \
            "${script}" internal-source "${from_source}"
    fi

    if ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        "${script}" internal-source "${name}"
    fi

    prepare_container

    if ! [ "${allow_source_writes}" = "yes" ]; then
        container_sources_ro=":ro"
    fi

    if ! [ -d "${base_dir}"/builds/$1 ]; then
        run_in_container internal-configure $1
    fi
    run_in_container internal-build $1
    rm -rf "${base_dir}"/pkgs/$1
    if ! run_in_container internal-package $1; then
        rm -rf "${base_dir}"/pkgs/$1
        return 1
    fi
    unset container_sources_ro

    destroy_container
}

cmd_host_build() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/host-recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-host-pkg "${pkg}"
        done
    done
}

cmd_build() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-pkg "${pkg}"
        done
    done
}

cmd_prepare() {
    for i in "$@"; do
        "${script}" internal-do-prepare "$i"
    done
}

cmd_host_rebuild() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/host-recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-host-rebuild "${pkg}"
        done
    done
}

cmd_rebuild() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-rebuild "${pkg}"
        done
    done
}


cmd_check_updates() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            unset repology_id
            unset repology_srcname
            unset skip_pkg_check

            . "${base_dir}/recipes/${pkg}"

            printf "checking $pkg ..."

            if [ "$skip_pkg_check" = "yes" ]; then
                printf ' \033[0;37;100mskipped\033[0m\n'
                continue
            fi

            if [ -z "$repology_id" ]; then
                name_to_check="$name"
            else
                name_to_check="$repology_id"
            fi

            if [ -z "$repology_srcname" ]; then
                srcname_to_check=""
            else
                srcname_to_check=".srcname==\"$repology_srcname\" and"
            fi

            sleep 1
            repology_response="$(curl -s -A '' https://repology.org/api/v1/project/$name_to_check)"
            checked_vers=$(echo "$repology_response" | jq '.[] | select('"$srcname_to_check"' (.repo=="arch" or .repo=="nix_unstable" or .repo=="chimera")).version' | sort -Vr | head -n 1)
            if [ -z "$checked_vers" ]; then
                checked_vers=$(echo "$repology_response" | jq '.[] | select('"$srcname_to_check"' .repo=="alpine_edge").version' | sort -Vr | head -n 1)
            fi
            if [ -z "$checked_vers" ]; then
                checked_vers=$(echo "$repology_response" | jq '.[] | select('"$srcname_to_check"' .repo=="debian_unstable").version' | sort -Vr | head -n 1)
            fi
            if [ -z "$checked_vers" ]; then
                checked_vers=$(echo "$repology_response" | jq '.[] | select('"$srcname_to_check"' .repo=="aur").version' | sort -Vr | head -n 1)
            fi
            if [ -z "$checked_vers" ]; then
                printf " \033[0;97;101mis not checkable\033[0m\n"
                continue
            fi

            checked_vers="$(echo "$checked_vers" | sed 's/\"//g')"

            if ! [ "$version" = "$checked_vers" ]; then
                if ! [ "$(printf "$checked_vers\n$version\n" | sort -Vr | head -n 1)" = "$version" ]; then
                    printf " \033[0;97;42mneeds update $version -> $checked_vers\033[0m\n"
                else
                    printf " \033[0;97;44mmore up-to-date than detected ($version vs $checked_vers)\033[0m\n"
                fi
                continue
            fi

            printf "\33[2K\r"
        done
    done
}

cmd_install() {
    sysroot="$1"
    shift 1
    mkdir -m 755 -p "${sysroot}"

    pkgs_to_install=""
    if [ "$1" = '*' ]; then
        for pkg in "${base_dir}"/recipes/*; do
            pkgs_to_install="${pkgs_to_install} $(basename "${pkg}")"
        done
    else
        for ppkg in "$@"; do
            for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
                deps="${deps} ${pkg}"
            done
        done

        make_temp
        deps_file="${tmp}"

        echo "* resolving dependencies..."

        get_deps_file

        pkgs_to_install="$(cat "${deps_file}")"
    fi

    make_temp
    all_files="${tmp}"

    pkg_dirs_to_install=""
    for pkg in ${pkgs_to_install}; do
        echo "* installing ${pkg}..."

        if ! [ -d "${build_dir}"/pkgs/${pkg} ]; then
            "${script}" internal-do-pkg "${pkg}"
        fi

        ( cd "${build_dir}"/pkgs/${pkg} && find . >>"${all_files}" )

        pkg_dirs_to_install="${pkg_dirs_to_install} ${pkg}/."
    done

    echo "* checking for conflicts..."

    make_temp
    all_files_sorted="${tmp}"

    make_temp
    all_files_uniq="${tmp}"

    sort <"${all_files}" >"${all_files_sorted}"
    uniq <"${all_files_sorted}" >"${all_files_uniq}"

    dup_elements="$(comm -23 "${all_files_sorted}" "${all_files_uniq}" | uniq)"

    rm -f "$JINX_CACHE_DIR/merged-info-dir"

    for pkg in ${pkgs_to_install}; do
        for elem in ${dup_elements}; do
            if [ -f "${build_dir}"/pkgs/${pkg}/${elem} ] || [ -L "${build_dir}"/pkgs/${pkg}/${elem} ]; then
                if [ "${elem}" = "./usr/share/info/dir" ]; then
                    # Coalesce info directory
                    if ! [ -f "$JINX_CACHE_DIR/merged-info-dir" ]; then
                        cp "${build_dir}"/pkgs/${pkg}/${elem} "$JINX_CACHE_DIR/merged-info-dir"
                    else
                        "$JINX_CACHE_DIR/merge-info" -o "$JINX_CACHE_DIR/merged-info-dir" "${build_dir}"/pkgs/${pkg}/${elem} "$JINX_CACHE_DIR/merged-info-dir"
                    fi
                    continue
                fi
                die "* error: duplicate files were found in package '${pkg}': ${elem}"
            fi
        done
    done

    echo "* synchronising package files to sysroot '${sysroot}'..."
    sysroot_abs="$(cd "${sysroot}" && pwd -P)"
    ( cd "${build_dir}/pkgs" && rsync -urlptD ${pkg_dirs_to_install} "${sysroot_abs}"/ )

    # inject the merged info dir into sysroot
    if [ -f "${sysroot}"/usr/share/info/dir ] && [ -f "$JINX_CACHE_DIR/merged-info-dir" ]; then
        "$JINX_CACHE_DIR/merge-info" -o "${sysroot}"/usr/share/info/dir "$JINX_CACHE_DIR/merged-info-dir" "${sysroot}"/usr/share/info/dir
    else
        if [ -f "$JINX_CACHE_DIR/merged-info-dir" ]; then
            cp "$JINX_CACHE_DIR/merged-info-dir" "${sysroot}"/usr/share/info/dir
        fi
    fi
}

rebuild_b2sum() {
    cat <<'EOF' >"$JINX_CACHE_DIR/b2sum.c"
// This blake2b implementation comes from the GNU coreutils project.
// https://github.com/coreutils/coreutils/blob/master/src/blake2/blake2b-ref.c

#include <stdbool.h>
#include <stdint.h>
#include <stddef.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define BLAKE2B_OUT_BYTES 64
#define BLAKE2B_BLOCK_BYTES 128
#define BLAKE2B_KEY_BYTES 64
#define BLAKE2B_SALT_BYTES 16
#define BLAKE2B_PERSONAL_BYTES 16

static const uint64_t blake2b_iv[8] = {
    0x6a09e667f3bcc908,
    0xbb67ae8584caa73b,
    0x3c6ef372fe94f82b,
    0xa54ff53a5f1d36f1,
    0x510e527fade682d1,
    0x9b05688c2b3e6c1f,
    0x1f83d9abfb41bd6b,
    0x5be0cd19137e2179,
};

static const uint8_t blake2b_sigma[12][16] = {
    {  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
    { 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
    { 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
    {  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
    {  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
    {  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 },
    { 12,  5,  1, 15, 14, 13,  4, 10,  0,  7,  6,  3,  9,  2,  8, 11 },
    { 13, 11,  7, 14, 12,  1,  3,  9,  5,  0, 15,  4,  8,  6,  2, 10 },
    {  6, 15, 14,  9, 11,  3,  0,  8, 12,  2, 13,  7,  1,  4, 10,  5 },
    { 10,  2,  8,  4,  7,  6,  1,  5, 15, 11,  9, 14,  3, 12, 13,  0 },
    {  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
    { 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
};

struct blake2b_state {
    uint64_t h[8];
    uint64_t t[2];
    uint64_t f[2];
    uint8_t buf[BLAKE2B_BLOCK_BYTES];
    size_t buf_len;
    uint8_t last_node;
};

struct blake2b_param {
    uint8_t digest_length;
    uint8_t key_length;
    uint8_t fan_out;
    uint8_t depth;
    uint32_t leaf_length;
    uint32_t node_offset;
    uint32_t xof_length;
    uint8_t node_depth;
    uint8_t inner_length;
    uint8_t reserved[14];
    uint8_t salt[BLAKE2B_SALT_BYTES];
    uint8_t personal[BLAKE2B_PERSONAL_BYTES];
} __attribute__((packed));

static void blake2b_increment_counter(struct blake2b_state *state, uint64_t inc) {
    state->t[0] += inc;
    state->t[1] += state->t[0] < inc;
}

static inline uint64_t rotr64(uint64_t w, unsigned c) {
    return (w >> c) | (w << (64 - c));
}

#define G(r, i, a, b, c, d) do { \
        a = a + b + m[blake2b_sigma[r][2 * i + 0]]; \
        d = rotr64(d ^ a, 32); \
        c = c + d; \
        b = rotr64(b ^ c, 24); \
        a = a + b + m[blake2b_sigma[r][2 * i + 1]]; \
        d = rotr64(d ^ a, 16); \
        c = c + d; \
        b = rotr64(b ^ c, 63); \
    } while (0)

#define ROUND(r) do { \
        G(r, 0, v[0], v[4], v[8], v[12]); \
        G(r, 1, v[1], v[5], v[9], v[13]); \
        G(r, 2, v[2], v[6], v[10], v[14]); \
        G(r, 3, v[3], v[7], v[11], v[15]); \
        G(r, 4, v[0], v[5], v[10], v[15]); \
        G(r, 5, v[1], v[6], v[11], v[12]); \
        G(r, 6, v[2], v[7], v[8], v[13]); \
        G(r, 7, v[3], v[4], v[9], v[14]); \
    } while (0)

static void blake2b_compress(struct blake2b_state *state, const uint8_t block[static BLAKE2B_BLOCK_BYTES]) {
    uint64_t m[16];
    uint64_t v[16];

    for (int i = 0; i < 16; i++) {
        m[i] = *(uint64_t *)(block + i * sizeof(m[i]));
    }

    for (int i = 0; i < 8; i++) {
        v[i] = state->h[i];
    }

    v[8] = blake2b_iv[0];
    v[9] = blake2b_iv[1];
    v[10] = blake2b_iv[2];
    v[11] = blake2b_iv[3];
    v[12] = blake2b_iv[4] ^ state->t[0];
    v[13] = blake2b_iv[5] ^ state->t[1];
    v[14] = blake2b_iv[6] ^ state->f[0];
    v[15] = blake2b_iv[7] ^ state->f[1];

    ROUND(0);
    ROUND(1);
    ROUND(2);
    ROUND(3);
    ROUND(4);
    ROUND(5);
    ROUND(6);
    ROUND(7);
    ROUND(8);
    ROUND(9);
    ROUND(10);
    ROUND(11);

    for (int i = 0; i < 8; i++) {
        state->h[i] = state->h[i] ^ v[i] ^ v[i + 8];
    }
}

#undef G
#undef ROUND

static void blake2b_init(struct blake2b_state *state) {
    struct blake2b_param param;
    memset(&param, 0, sizeof(struct blake2b_param));

    param.digest_length = BLAKE2B_OUT_BYTES;
    param.fan_out = 1;
    param.depth = 1;

    memset(state, 0, sizeof(struct blake2b_state));

    for (int i = 0; i < 8; i++) {
        state->h[i] = blake2b_iv[i];
    }

    for (int i = 0; i < 8; i++) {
        state->h[i] ^= *(uint64_t *)((void *)&param + sizeof(state->h[i]) * i);
    }
}

static void blake2b_update(struct blake2b_state *state, const void *in, size_t in_len) {
    if (in_len == 0) {
        return;
    }

    size_t left = state->buf_len;
    size_t fill = BLAKE2B_BLOCK_BYTES - left;

    if (in_len > fill) {
        state->buf_len = 0;

        memcpy(state->buf + left, in, fill);
        blake2b_increment_counter(state, BLAKE2B_BLOCK_BYTES);
        blake2b_compress(state, state->buf);

        in += fill;
        in_len -= fill;

        while (in_len > BLAKE2B_BLOCK_BYTES) {
            blake2b_increment_counter(state, BLAKE2B_BLOCK_BYTES);
            blake2b_compress(state, in);

            in += fill;
            in_len -= fill;
        }
    }

    memcpy(state->buf + state->buf_len, in, in_len);
    state->buf_len += in_len;
}

static void blake2b_final(struct blake2b_state *state, void *out) {
    uint8_t buffer[BLAKE2B_OUT_BYTES] = {0};

    blake2b_increment_counter(state, state->buf_len);
    state->f[0] = (uint64_t)-1;
    memset(state->buf + state->buf_len, 0, BLAKE2B_BLOCK_BYTES - state->buf_len);
    blake2b_compress(state, state->buf);

    for (int i = 0; i < 8; i++) {
        *(uint64_t *)(buffer + sizeof(state->h[i]) * i) = state->h[i];
    }

    memcpy(out, buffer, BLAKE2B_OUT_BYTES);
    memset(buffer, 0, sizeof(buffer));
}

static void blake2b(void *out, const void *in, size_t in_len) {
    struct blake2b_state state = {0};

    blake2b_init(&state);
    blake2b_update(&state, in, in_len);
    blake2b_final(&state, out);
}

int main(int argc, char *argv[]) {
    if (argc < 2) {
        return EXIT_FAILURE;
    }

    FILE *f = fopen(argv[1], "r");
    if (f == NULL) {
        return EXIT_FAILURE;
    }

    fseek(f, 0, SEEK_END);
    size_t f_size = ftell(f);
    rewind(f);

    void *mem = malloc(f_size);
    if (mem == NULL) {
        return EXIT_FAILURE;
    }

    if (fread(mem, f_size, 1, f) != 1) {
        return EXIT_FAILURE;
    }

    uint8_t out_buf[BLAKE2B_OUT_BYTES];
    blake2b(out_buf, mem, f_size);

    for (size_t i = 0; i < BLAKE2B_OUT_BYTES; i++) {
        printf("%02x", out_buf[i]);
    }

    printf("  %s\n", argv[1]);
}
EOF
    cc -O2 -pipe -fno-strict-aliasing -Wall -Wextra "$JINX_CACHE_DIR/b2sum.c" -o "$JINX_CACHE_DIR/b2sum"
}

rebuild_rbrt() {
    cat <<'EOF' >"$JINX_CACHE_DIR/rbrt.c"
// Written by 48cf (iretq@riseup.net)
// Inspired heavily by https://github.com/managarm/cbuildrt/

#define _GNU_SOURCE

#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>
#include <errno.h>
#include <unistd.h>
#include <fcntl.h>
#include <sched.h>
#include <sys/mount.h>
#include <sys/wait.h>

#define STRINGIFY(x) #x
#define TOSTRING(x) STRINGIFY(x)

int main(int argc, char *argv[]) {
    int ok = 1;
    const char *err_msg = "";

    char *rootfs = NULL;
    char **mounts = NULL;
    char **envs = NULL;
    char **process_args = NULL;

    int mount_count = 0;
    int mounts_size = 0;

    int env_count = 0;
    int envs_size = 0;

    bool rw_root = false;
    bool unshare_net = false;

    int uid = -1, gid = -1;
    int euid = geteuid();
    int egid = getegid();

    int setgroups_fd = -1;
    int uid_map_fd = -1;
    int gid_map_fd = -1;

    char *workdir = "/";

    for (int i = 1; i < argc; ) {
        if (strcmp(argv[i], "--workdir") == 0) {
            workdir = argv[i + 1];
            i += 2;
        } else if (strcmp(argv[i], "-r") == 0 || strcmp(argv[i], "--root") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            rootfs = argv[i + 1];
            i += 2;

            if (i < argc - 1 && strcmp(argv[i], "rw") == 0) {
                rw_root = true;
                i++;
            }
        } else if (strcmp(argv[i], "-u") == 0 || strcmp(argv[i], "--uid") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (sscanf(argv[i + 1], "%d", &uid) != 1) {
                fprintf(stderr, "%s: '%s' is not a valid user ID\n", argv[0], argv[i + 1]);
                goto cleanup;
            }

            i += 2;
        } else if (strcmp(argv[i], "-g") == 0 || strcmp(argv[i], "--gid") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (sscanf(argv[i + 1], "%d", &gid) != 1) {
                fprintf(stderr, "%s: '%s' is not a valid group ID\n", argv[0], argv[i + 1]);
                goto cleanup;
            }

            i += 2;
        } else if (strncmp(argv[i], "-m", 2) == 0) {
            if (mount_count == mounts_size) {
                mounts_size = mounts_size == 0 ? 16 : mounts_size * 2;
                char **tmp_mounts = realloc(mounts, sizeof(char *) * mounts_size);
                if (tmp_mounts == NULL) {
                    fprintf(stderr, "%s: failed to allocate mounts array\n", argv[0]);
                    goto cleanup;
                }
                mounts = tmp_mounts;
            }

            char *target = argv[i] + 2;
            while (*target && *target != ':') {
                target++;
            }

            if (!*target) {
                fprintf(stderr, "%s: mount points need to be provided in the 'source:target' format\n", argv[0]);
                goto cleanup;
            }

            mounts[mount_count++] = argv[i] + 2;
            i += 1;
        } else if (strcmp(argv[i], "-e") == 0 || strcmp(argv[i], "--env") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (env_count == envs_size) {
                envs_size = envs_size == 0 ? 16 : envs_size * 2;
                char **tmp_envs = realloc(envs, sizeof(char *) * envs_size);
                if (tmp_envs == NULL) {
                    fprintf(stderr, "%s: failed to allocate environment variables array\n", argv[0]);
                    goto cleanup;
                }
                envs = tmp_envs;
            }

            char *value = argv[i + 1];
            while (*value && *value != '=') {
                value++;
            }

            if (!*value) {
                fprintf(stderr, "%s: environment variables need to be provided in the 'key=value' format\n", argv[0]);
                goto cleanup;
            }

            envs[env_count++] = argv[i + 1];
            i += 2;
        } else if (strcmp(argv[i], "-n") == 0 || strcmp(argv[i], "--net") == 0) {
            unshare_net = true;
            i += 1;
        } else if (strcmp(argv[i], "--") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: at least one trailing argument is required\n", argv[0]);
                goto cleanup;
            }

            process_args = &argv[i + 1];
            break;
        } else {
            fprintf(stderr, "%s: unrecognized option '%s'\n", argv[0], argv[i]);
            goto cleanup;
        }
    }

    if (rootfs == NULL) {
        fprintf(stderr, "%s: root file system path is required\n", argv[0]);
        goto cleanup;
    }

    if (process_args == NULL) {
        fprintf(stderr, "%s: process arguments are requires\n", argv[0]);
        goto cleanup;
    }

    if (uid == -1 || gid == -1) {
        fprintf(stderr, "%s: user and group IDs are both required\n", argv[0]);
        goto cleanup;
    }

    if (unshare(CLONE_NEWUSER | CLONE_NEWPID) < 0) {
        err_msg = "unshare() failure at line " TOSTRING(__LINE__);
        goto errno_error;
    }

    char uid_map[64], gid_map[64];

    int uid_map_len = snprintf(uid_map, 64, "%d %d 1", uid, euid);
    int gid_map_len = snprintf(gid_map, 64, "%d %d 1", gid, egid);

    setgroups_fd = open("/proc/self/setgroups", O_RDWR);
    if (setgroups_fd < 0 || write(setgroups_fd, "deny", 4) < 0) {
        err_msg = "failed to open or write to /proc/self/setgroups at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(setgroups_fd);
    setgroups_fd = -1;

    uid_map_fd = open("/proc/self/uid_map", O_RDWR);
    if (uid_map_fd < 0 || write(uid_map_fd, uid_map, uid_map_len) < 0) {
        err_msg = "failed to open or write to /proc/self/uid_map at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(uid_map_fd);
    uid_map_fd = -1;

    gid_map_fd = open("/proc/self/gid_map", O_RDWR);
    if (gid_map_fd < 0 || write(gid_map_fd, gid_map, gid_map_len) < 0) {
        err_msg = "failed to open or write to /proc/self/gid_map at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(gid_map_fd);
    gid_map_fd = -1;

    if (setuid(uid) < 0 || setgid(gid) < 0) {
        err_msg = "setuid()/setgid() failure at line " TOSTRING(__LINE__);
        goto errno_error;
    }

    int child_pid = fork();
    if (child_pid == 0) {
        if (unshare(CLONE_NEWNS) < 0) {
            err_msg = "unshare() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (mount(rootfs, rootfs, NULL, MS_BIND, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        int root_flags = MS_REMOUNT | MS_BIND | MS_NOSUID | MS_NODEV;

        if (!rw_root) {
            root_flags |= MS_RDONLY;
        }

        if (mount(rootfs, rootfs, NULL, root_flags, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        char target_path[PATH_MAX];

        snprintf(target_path, PATH_MAX, "%s/etc/resolv.conf", rootfs);
        if (mount("/etc/resolv.conf", target_path, NULL, MS_BIND, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/dev", rootfs);
        if (mount("/dev", target_path, NULL, MS_REC | MS_BIND | MS_SLAVE, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/sys", rootfs);
        if (mount("/sys", target_path, NULL, MS_REC | MS_BIND | MS_SLAVE, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/run", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/tmp", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/var/tmp", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/proc", rootfs);
        if (mount(NULL, target_path, "proc", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        for (int i = 0; i < mount_count; i++) {
            char *source = mounts[i];
            char *target = source;

            while (*target && *target != ':') {
                target++;
            }

            *target++ = 0;

            char *read_only = target;

            while (*read_only && *read_only != ':') {
                read_only++;
            }

            bool ro = false;
            if (*read_only == ':') {
                *read_only++ = 0;
                ro = strcmp(read_only, "ro") == 0;
            }

            snprintf(target_path, PATH_MAX, "%s%s", rootfs, target);
            if (mount(source, target_path, NULL, MS_BIND | (ro ? MS_RDONLY : 0), NULL) < 0) {
                err_msg = "mount() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }
            if (ro) {
                if (mount(source, target_path, NULL, MS_REMOUNT | MS_BIND | MS_RDONLY, NULL) < 0) {
                    err_msg = "mount() failure at line " TOSTRING(__LINE__);
                    goto errno_error;
                }
            }
        }

        if (unshare_net && unshare(CLONE_NEWNET) < 0) {
            err_msg = "unshare() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (chroot(rootfs) < 0) {
            err_msg = "chroot() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (chdir(workdir) < 0) {
            err_msg = "chdir() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        int child = fork();
        if (child == 0) {
            clearenv();

            setenv("HOME", "/root", 1);
            setenv("LANG", "C", 1);
            setenv("PATH", "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", 1);

            for (int i = 0; i < env_count; i++) {
                char *key = envs[i];
                char *value = key;

                while (*value && *value != '=') {
                    value++;
                }

                *value++ = 0;
                setenv(key, value, 1);
            }

            if (execvp(process_args[0], process_args) < 0) {
                err_msg = "execvp() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }

            __builtin_unreachable();
        } else {
            int exit_code = -1;
            if (waitpid(child, &exit_code, 0) < 0) {
                err_msg = "waitpid() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }

            ok = WEXITSTATUS(exit_code);
            goto cleanup;
        }

        __builtin_unreachable();
    } else {
        int exit_code = -1;
        if (waitpid(child_pid, &exit_code, 0) < 0) {
            err_msg = "waitpid() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        ok = WEXITSTATUS(exit_code);
        goto cleanup;
    }

errno_error:
    fprintf(stderr, "%s: %s: %s\n", argv[0], err_msg, strerror(errno));

cleanup:
    if (mounts != NULL) {
        free(mounts);
    }
    if (envs != NULL) {
        free(envs);
    }
    if (setgroups_fd >= 0) {
        close(setgroups_fd);
    }
    if (uid_map_fd >= 0) {
        close(uid_map_fd);
    }
    if (gid_map_fd >= 0) {
        close(gid_map_fd);
    }

    return ok;
}
EOF
    cc -O2 -pipe -Wall -Wextra "$JINX_CACHE_DIR/rbrt.c" -o "$JINX_CACHE_DIR/rbrt"
}

reinit_container() {
    chmod -R 777 "$JINX_CACHE_DIR/sets" 2>/dev/null || true
    chmod -R 777 "$JINX_CACHE_DIR/apt-cache" 2>/dev/null || true
    rm -rf "$JINX_CACHE_DIR/debian-rootfs.tar.xz" "$JINX_CACHE_DIR/sets" "$JINX_CACHE_DIR/apt-cache"

    make_dir "${apt_cache}"

    curl -Lo "$JINX_CACHE_DIR/debian-rootfs.tar.xz" https://github.com/mintsuki/debian-rootfs/releases/download/${debian_snapshot}/debian-rootfs-${debian_architecture}.tar.xz
    if ! "$JINX_CACHE_DIR/b2sum" "$JINX_CACHE_DIR/debian-rootfs.tar.xz" | grep "${debian_rootfs_b2sum}" >/dev/null 2>&1; then
        die "Jinx: Failed to verify Debian rootfs tarball"
    fi
    ( cd "$JINX_CACHE_DIR" && xzcat debian-rootfs.tar.xz | tar -xf - )
    rm "$JINX_CACHE_DIR/debian-rootfs.tar.xz"
    make_dir "$JINX_CACHE_DIR/sets"
    mv "$JINX_CACHE_DIR/debian-rootfs-${debian_architecture}" "$JINX_CACHE_DIR/sets/.image"

    echo 'en_US.UTF-8 UTF-8' > "$JINX_CACHE_DIR/sets/.image/etc/locale.gen"
    echo 'APT::Install-Suggests "0";
APT::Install-Recommends "0";
APT::Sandbox::User "root";
Acquire::Check-Valid-Until "0";' >> "$JINX_CACHE_DIR/sets/.image/etc/apt/apt.conf"

    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get update
    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get install -y locales
    run_in_container1 "$JINX_CACHE_DIR/sets/.image" locale-gen

    # Fix permissions of files
    for f in $(find "$JINX_CACHE_DIR/sets/.image" -perm 000 2>/dev/null); do
        chmod 755 "$f"
    done

    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get install -y autopoint bash bison bzip2 curl diffutils docbook-xsl doxygen file findutils flex gawk gettext grep gzip xsltproc m4 make patch perl python3 sed tar texinfo w3m which xmlto xz-utils

    # Build xstow
    XSTOW_BUILDENV="$JINX_CACHE_DIR/xstow_buildenv"
    cp -Pprf "$JINX_CACHE_DIR/sets/.image/." "${XSTOW_BUILDENV}/"
    curl -Lo "${XSTOW_BUILDENV}/xstow-${XSTOW_VERSION}.tar.gz" https://github.com/majorkingleo/xstow/releases/download/${XSTOW_VERSION}/xstow-${XSTOW_VERSION}.tar.gz
    ( cd "${XSTOW_BUILDENV}" && gunzip < xstow-${XSTOW_VERSION}.tar.gz | tar -xf - )
    run_in_container1 "${XSTOW_BUILDENV}" apt-get install -y build-essential
    run_in_container1 "${XSTOW_BUILDENV}" sh -c "cd /xstow-${XSTOW_VERSION} && ./configure LDFLAGS='-static' --enable-static --enable-merge-info --without-curses && make -j${parallelism}"
    mv "${XSTOW_BUILDENV}/xstow-${XSTOW_VERSION}/src/merge-info" "$JINX_CACHE_DIR/"
    chmod -R 777 "$XSTOW_BUILDENV"
    rm -rf "$XSTOW_BUILDENV"
}

first_use() {
    echo "* preparing Jinx cache..."

    make_dir "$JINX_CACHE_DIR"

    rebuild_b2sum
    rebuild_rbrt

    reinit_container

    echo "$jinx_version" > "$JINX_CACHE_DIR/version"

    echo "* done"
}

redo_first_use() {
    echo "* purging old Jinx cache..."
    chmod -R 777 "$JINX_CACHE_DIR" || true
    rm -rf "$JINX_CACHE_DIR"
    first_use
}

if ! [ -f "$JINX_CONFIG_FILE" ]; then
    die "$0: missing Jinx config file '$JINX_CONFIG_FILE'"
fi

. "${JINX_CONFIG_FILE}"

if [ -z "$JINX_MAJOR_VER" ]; then
    die "$0: required config variable \$JINX_MAJOR_VER missing"
fi

if ! [ "$JINX_MAJOR_VER" = "$jinx_major_ver" ]; then
    die "$0: needed major version ($JINX_MAJOR_VER) differs from Jinx-provided major version ($jinx_major_ver)"
fi

if ! [ -d "$JINX_CACHE_DIR" ]; then
    first_use
fi

if ! [ -f "$JINX_CACHE_DIR/version" ] || ! [ "$(cat "$JINX_CACHE_DIR/version")" = "$jinx_version" ]; then
    redo_first_use
fi

case "$1" in
    internal-prepare)
        do_prepare "$2"
        ;;
    internal-precont-patch)
        precont_patch "$2"
        ;;
    internal-cont-patch)
        cont_patch "$2"
        ;;
    internal-configure-host)
        do_configure_host "$2"
        ;;
    internal-build-host)
        do_build_host "$2"
        ;;
    internal-package-host)
        do_package_host "$2"
        ;;
    internal-configure)
        do_configure "$2"
        ;;
    internal-build)
        do_build "$2"
        ;;
    internal-package)
        do_package "$2"
        ;;
    internal-get-deps-file)
        . "${base_dir}"/recipes/$2
        deps_file="$3"
        get_deps_file
        ;;
    internal-get-hostdeps-file-run)
        . "${base_dir}"/host-recipes/$2
        hostdeps_file="$3"
        get_hostdeps_file_run
        ;;
    internal-source)
        do_source "$2"
        ;;
    internal-do-host-pkg)
        do_host_pkg "$2"
        ;;
    internal-do-pkg)
        do_pkg "$2"
        ;;
    internal-do-prepare)
        do_cmd_prepare "$2"
        ;;
    internal-do-host-rebuild)
        do_cmd_host_rebuild "$2"
        ;;
    internal-do-rebuild)
        do_cmd_rebuild "$2"
        ;;
    host-build)
        shift 1
        cmd_host_build "$@"
        ;;
    build)
        shift 1
        cmd_build "$@"
        ;;
    regenerate|regen)
        shift 1
        cmd_prepare "$@"
        ;;
    host-rebuild)
        shift 1
        cmd_host_rebuild "$@"
        ;;
    rebuild)
        shift 1
        cmd_rebuild "$@"
        ;;
    check-updates)
        shift 1
        cmd_check_updates "$@"
        ;;
    install)
        shift 1
        cmd_install "$@"
        ;;
    rbrt)
        rebuild_rbrt
        ;;
    rebuild-cache)
        redo_first_use
        ;;
    *)
        if [ -z "$1" ]; then
            die "$0: no command specified."
        else
            die "$0: unknown command: $1"
        fi
        ;;
esac
