#! /bin/sh

# Copyright (C) 2022-2025 mintsuki

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

set -e

IFS=" ""	"'
'

LC_COLLATE=C
export LC_COLLATE

umask 0022

jinx_major_ver="0.6"
jinx_minor_ver="0"

jinx_version="${jinx_major_ver}.${jinx_minor_ver}"

debian_snapshot="20250627T143139Z"

XBPS_VERSION=0.60.5
XBPS_B2SUM=91aad926f25e78c17b2646f2e478e9a4141d9d80ebb93bc821c91333c8f5b5cf72a08edb7f25aef486e0761f15da8322207474c3b6f546d6403dd424cc442525

die() {
    echo "$1"
    exit 1
}

if [ -z "$1" ]; then
    die "$0: no command specified."
fi

cmd_help() {
    echo "usage: $0 <command> <package(s)>"
    printf "\n   help|--help        Displays this message"
    printf "\n   version|--version  Prints the version"
    printf "\n   init               Initialises a build directory"
    printf "\n   build              Builds package(s), does incremental builds"
    printf "\n   build-if-needed    Builds package(s) if necessary"
    printf "\n   rebuild            Rebuilds package(s)"
    printf "\n   host-build         Same as build, but for host package(s)"
    printf "\n   host-rebuild       Same as rebuild, but for host package(s)"
    printf "\n   regenerate|regen   Regenerates patch for package(s) and re-runs prepare step"
    printf "\n   install            Installs package(s)"
    printf "\n   reinstall          Reinstalls package(s)"
    printf "\n   rebuild-cache      Rebuilds Jinx cache"
    printf "\n\nexample: $0 build-if-needed '*'\n"
}

cmd_init() {
    if ! [ -f "$1"/Jinxfile ]; then
        die "$0: Provided source directory contains no Jinxfile"
    fi

    srcdir="$1"

    if [ -f ".jinx-parameters" ]; then
        die "$0: Current directory already initialised, run '$0 deinit' first"
    fi

    if [ -f "Jinxfile" ]; then
        die "$0: In-tree builds are not supported"
    fi

    cat <<EOF >.jinx-parameters
#! /bin/sh

JINX_SOURCE_DIR="${srcdir}"
JINX_ARCH="$(uname -m)"
EOF

    shift 1

    for p in "$@"; do
        echo "JINX_$p" | sed 's/=/="/g;s/$/"/g' >>.jinx-parameters
    done

    echo "Initialised with '${srcdir}' as source directory"
}

case "$1" in
    version|--version)
        echo "Jinx version $jinx_version"
        exit 0
        ;;
    help|--help)
        cmd_help
        exit 0
        ;;
    init)
        shift 1
        cmd_init "$@"
        exit 0
        ;;
esac

if ! [ "$(uname -s)" = "Linux" ]; then
    die "$0: Jinx only supports running on Linux hosts."
fi

case "$1" in
    install)
        ;;
    *)
        if [ "$(id -u)" = "0" ]; then
            die "$0: Jinx does not support running as root."
        fi
        ;;
esac

case "$(uname -m)" in
    x86_64)
        debian_architecture=amd64
        debian_rootfs_b2sum=d4a485b1c5577b442f5d2d7c13fbe6fff3cd4fa811353bafef0835e78b12b3fb1d954a1a3bdedffc325a9b871a087f83fadac9ce70fbba2a70179b85996a73a6
        ;;
    aarch64)
        debian_architecture=arm64
        debian_rootfs_b2sum=bfd6a4827125a4b7841f320e96d539c9bbe81c3463fed53eae1f9079b18939bca8e2b371f06ff109a68887627f7c40fabe384d18ac1ebb69f69cf05c085845c9
        ;;
    arm*)
        debian_architecture=armhf
        debian_rootfs_b2sum=5add0809bd3e27a9f7d3e7809c057433a24bd4c831d4a55f7dc2ce536a9811f1e58a104cc2335d5511bae02062efdfc7410666504b9648ae8f87dc68828620c2
        ;;
    i?86)
        debian_architecture=i386
        debian_rootfs_b2sum=6979e88402aec598387a520108680f0b670be12101582dfebdd4dd6d0fa3e0187780d61c7dc1079818b4c844cc27d660c4ca1c8fb23510931d87ba2501e63d39
        ;;
    mips64el)
        debian_architecture=mips64el
        debian_rootfs_b2sum=7ea8dea44faa22b34ca4ddfa529234e85e4e7176ac00907f98058eb05da828b47c8af1f2d3a18019ce2bca2b153d495347212d2ba790b62c1bc1fe8d71c2a7cf
        ;;
    ppc64le)
        debian_architecture=ppc64el
        debian_rootfs_b2sum=fe6343f447bc8d24031cce9f1ba0d2cd469e0f52769cbdca84ca005524ee2322c4af2672ee44b1867d75245f891456ccf1eaf3818604cf8cf2ca60f72232195b
        ;;
    riscv64)
        debian_architecture=riscv64
        debian_rootfs_b2sum=8972fb0ea5a55d10bef1a3d2cef47a796cac16d3f7ad1070a6e1484ff90590a8870cf145db78a536a8ffc8303b6344559c03f56fb605b47eccfd221531827d64
        ;;
    s390x)
        debian_architecture=s390x
        debian_rootfs_b2sum=7714135320e5f021ed400c28b718b5e2f8be8b173f74d504f3c95d97dd8ed1c4698b171fb04525cb9756fc8fc63d0cf90ed604abb071a43ae8b24300c512020d
        ;;
    *)
        die "$0: Unsupported architecture: $(uname -m)"
        ;;
esac

make_dir() {
    for d in "$@"; do
        mkdir -p "$d"
        dn="$(cd "$d" && pwd -P)"
        while true; do
            if [ "$dn" = "$base_dir" ] || [ "$dn" = "$build_dir" ] || [ "$dn" = "/" ]; then
                break
            fi
            chmod 755 "$dn"
            dn="$(dirname "$dn")"
        done
    done
}

script_name="$(basename "$0")"
script_dir="$(dirname "$0")"
if [ "$script_dir" = "." ] || [ -z "$script_dir" ]; then
    if echo "$0" | grep "/" >/dev/null 2>&1; then
        script_dir=.
    else
        script_dir="$(dirname $(which "${script_name}"))"
    fi
fi
script_dir="$(cd "${script_dir}" && pwd -P)"
script="${script_dir}/${script_name}"

in_container=false
if [ "$script" = "/base_dir/jinx" ]; then
    in_container=true
fi

if [ -z "$JINX_PARALLELISM" ]; then
    max_threads_by_mem="$(( ((($(free | awk '/^Mem:/{print $2}') + 1048575) / 1048576) + 1) / 2 ))"
    parallelism="$(nproc 2>/dev/null || echo 1)"
    parallelism="$(( $parallelism < $max_threads_by_mem ? $parallelism : $max_threads_by_mem ))"
else
    parallelism="$JINX_PARALLELISM"
fi

if [ "$in_container" = "false" ]; then
    build_dir="$(pwd -P)"
else
    build_dir=/build_dir
fi

if ! [ -f "${build_dir}"/.jinx-parameters ]; then
    die "$0: Please run '$0 init <source dir> <parameters>' first"
fi

. "${build_dir}"/.jinx-parameters

if [ "$in_container" = "false" ]; then
    base_dir="$(cd "$JINX_SOURCE_DIR" && pwd -P)"
else
    base_dir=/base_dir
fi

JINX_CONFIG_FILE="${base_dir}/Jinxfile"

if ! [ -d "$(dirname "$JINX_CONFIG_FILE")" ]; then
    die "$0: cannot access Jinxfile directory"
fi
JINX_CONFIG_FILE="$(cd "$(dirname "$JINX_CONFIG_FILE")" && pwd -P)"/"$(basename "$JINX_CONFIG_FILE")"

if [ -z "$JINX_CACHE_DIR" ]; then
    JINX_CACHE_DIR="${base_dir}/.jinx-cache"
fi
if ! [ -d "$(dirname "$JINX_CACHE_DIR")" ]; then
    die "$0: cannot access cache directory parent"
fi

if [ "$in_container" = "false" ]; then
    make_dir "$JINX_CACHE_DIR"
    JINX_CACHE_DIR="$(cd "$JINX_CACHE_DIR" && pwd -P)"

    make_dir "${base_dir}/sources" "${build_dir}/host-builds" "${build_dir}/host-pkgs" "${build_dir}/builds" "${build_dir}/pkgs"
fi

apt_cache="$JINX_CACHE_DIR/apt-cache"

temp_collect=""
trap 'eval rm -rf "$temp_collect"' EXIT

make_temp() {
    tmp="$(mktemp "$JINX_CACHE_DIR/tmp.XXXXXXXX")"
    temp_collect="${temp_collect} \"${tmp}\""
    if [ "$1" = "-d" ]; then
        rm -f "${tmp}"
        make_dir "${tmp}"
    fi
}

build_hostdeps() {
    for hostdep in ${hostdeps} ${hostrundeps}; do
        [ -f "${base_dir}"/host-recipes/${hostdep} ] || die "missing host dependency '${hostdep}' for recipe '${name}'"

        [ -d "${build_dir}"/host-pkgs/${hostdep} ] && continue

        "${script}" host-build ${hostdep}
    done
}

build_deps() {
    for dep in ${deps} ${builddeps}; do
        [ -f "${base_dir}"/recipes/${dep} ] || die "missing dependency '${dep}' for recipe '${name}'"

        (
            set -e
            unset version
            unset from_source
            . "${base_dir}"/recipes/${dep}
            if ! [ -z "${from_source}" ]; then
                version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            fi

            [ -f "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps ]
        ) && continue

        "${script}" build ${dep}
    done
}

get_hostdeps_file_run() {
    deps_to_do=""

    for hostdep in ${hostrundeps}; do
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${hostdep}"
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || printf " ${hostdep} " >> "${hostdeps_file}"
    done

    for hostdep in ${deps_to_do}; do
        "${script}" internal-get-hostdeps-file-run ${hostdep} "${hostdeps_file}"
    done
}

get_hostdeps_file() {
    deps_to_do=""

    for hostdep in ${hostdeps} ${hostrundeps}; do
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${hostdep}"
        grep " ${hostdep} " "${hostdeps_file}" >/dev/null 2>&1 || printf " ${hostdep} " >> "${hostdeps_file}"
    done

    for hostdep in ${deps_to_do}; do
        "${script}" internal-get-hostdeps-file-run ${hostdep} "${hostdeps_file}"
    done
}

get_builddeps_file() {
    deps_to_do=""

    for dep in ${deps} ${builddeps}; do
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${dep}"
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || printf " ${dep} " >> "${deps_file}"
    done

    for dep in ${deps_to_do}; do
        "${script}" internal-get-deps-file ${dep} "${deps_file}"
    done
}

get_deps_file() {
    deps_to_do=""

    for dep in ${deps}; do
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || deps_to_do="${deps_to_do} ${dep}"
        grep " ${dep} " "${deps_file}" >/dev/null 2>&1 || printf " ${dep} " >> "${deps_file}"
    done

    for dep in ${deps_to_do}; do
        "${script}" internal-get-deps-file ${dep} "${deps_file}"
    done
}

run_in_container1() {
    run_in_cont1_root="$1"
    shift 1

    make_dir "$run_in_cont1_root"/jinx-cache

    nochown_so=""
    if [ -f "$JINX_CACHE_DIR/nochown.so" ]; then
        nochown_so="--env LD_PRELOAD=/jinx-cache/nochown.so"
    fi

    "$JINX_CACHE_DIR/rbrt" \
        --root "$run_in_cont1_root" rw \
        --uid 0 \
        --gid 0 \
        --env HOME=/root \
        --env LANG=en_US.UTF-8 \
        --env LC_COLLATE=C \
        --env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin \
        --env LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib:/usr/lib64:/usr/lib \
        --env DEBIAN_FRONTEND=noninteractive \
        ${nochown_so} \
        -m"${apt_cache}":/var/cache/apt/archives \
        -m"$JINX_CACHE_DIR":/jinx-cache:ro \
        -- \
        "$@"

    rm -rf "$run_in_cont1_root"/jinx-cache
}

check_duplicates() {
    for elem in $(cd "$1" && find .); do
        if [ -f "$2"/${elem} ] || [ -L "$2"/${elem} ]; then
            return 1
        fi
    done
}

prepare_container() {
    cd "${build_dir}"

    make_temp
    hostdeps_file="${tmp}"
    make_temp
    deps_file="${tmp}"

    build_hostdeps
    build_deps

    get_hostdeps_file
    get_builddeps_file

    make_temp -d
    container_pkgs="${tmp}"
    make_temp -d
    sysroot_dir="${tmp}"

    for dep in $(cat "${deps_file}"); do
        XBPS_ARCH=invalid \
        XBPS_TARGET_ARCH="${JINX_ARCH}" \
            "$JINX_CACHE_DIR"/xbps-bin/xbps-install -y -r "${sysroot_dir}" -R "${build_dir}"/pkgs "${dep}" >/dev/null 2>&1
    done

    if [ "$JINX_NATIVE_MODE" = "yes" ] && [ -z "$cross_compile" ]; then
        imgroot="${sysroot_dir}"
    else
        for hostdep in $(cat "${hostdeps_file}"); do
            if ! check_duplicates "${build_dir}"/host-pkgs/${hostdep}/usr/local "${container_pkgs}"; then
                die "jinx: error: Dependency '${hostdep}' contains file confilcts"
            fi
            cp -Pplr "${build_dir}"/host-pkgs/${hostdep}/usr/local/. "${container_pkgs}"/
        done

        imagedeps="$(echo "${imagedeps}" | xargs -n1 | sort -u | xargs)"

        pkgset=""
        for pkg in ${imagedeps}; do
            pkgset="${pkgset}${pkg}/"

            if [ -f "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid" ]; then
                continue
            fi

            rm -rf "$JINX_CACHE_DIR/sets/${pkgset}"
            make_dir "$JINX_CACHE_DIR/sets/${pkgset}"

            want_link='l'
            want_experimental=''
            if echo "${pkg}" | grep -q '^experimental:'; then
                want_link=''
                want_experimental='-t experimental'
                pkg="$(echo "${pkg}" | sed 's/^experimental://g')"
            fi

            cp -Pp${want_link}rf "$JINX_CACHE_DIR/sets/${pkgset}../.image" "$JINX_CACHE_DIR/sets/${pkgset}.image"

            rm -f "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid"

            run_in_container1 "$JINX_CACHE_DIR/sets/${pkgset}.image" apt-get install -y ${want_experimental} "${pkg}"

            # Fix permissions of files
            for f in $(find "$JINX_CACHE_DIR/sets/${pkgset}.image" -perm 000 2>/dev/null); do
                chmod 755 "$f"
            done

            touch "$JINX_CACHE_DIR/sets/${pkgset}.image/.jinx-set-valid"
        done

        imgroot="$JINX_CACHE_DIR/sets/${pkgset}.image"
    fi
}

run_in_container() {
    if [ "${allow_network}" = "yes" ]; then
        unshare_net_flag=""
    else
        unshare_net_flag="-n"
    fi

    if [ ! -z "$TERM" ]; then
        run_in_cont_term="--env TERM=\"$TERM\""
    fi

    if ! [ -z "$COLORTERM" ]; then
        run_in_cont_colorterm="--env COLORTERM=\"$COLORTERM\""
    fi

    make_dir "${imgroot}/base_dir" "${imgroot}/sources" "${imgroot}/build_dir"

    native_mode_mounts=""
    if ( [ "$JINX_NATIVE_MODE" = "yes" ] && [ "$cross_compile" = "yes" ] ) || ( ! [ "$JINX_NATIVE_MODE" = "yes" ] ); then
        make_dir "${imgroot}/sysroot"

        container_pkgs_native_mount="-m${container_pkgs}:/usr/local:ro"
        sysroot_native_mount="-m${sysroot_dir}:/sysroot:ro"

        run_in_cont_lang=en_US.UTF-8
    else
        if ! [ -z "$JINX_NATIVE_LANG" ]; then
            run_in_cont_lang="$JINX_NATIVE_LANG"
        else
            run_in_cont_lang=C
        fi
    fi

    run_in_cont_argvar=""
    for arg in "$@"; do
        run_in_cont_argvar="$run_in_cont_argvar \"$arg\""
    done

    shadow_git_dir_build=""
    if [ -d "${build_dir}"/.git ]; then
        make_temp -d
        shadow_git_dir_build="-m${tmp}:/build_dir/.git"
    fi

    shadow_git_dir_base=""
    if [ -d "${base_dir}"/.git ]; then
        make_temp -d
        shadow_git_dir_base="-m${tmp}:/base_dir/.git"
    fi

    nochown_so=""
    if [ -f "$JINX_CACHE_DIR/nochown.so" ]; then
        nochown_so="--env LD_PRELOAD=/base_dir/.jinx-cache/nochown.so"
    fi

    "$JINX_CACHE_DIR/rbrt" \
        --root "${imgroot}" \
        --uid $(id -u) \
        --gid $(id -g) \
        --env HOME=/root \
        --env LANG=${run_in_cont_lang} \
        --env LC_COLLATE=C \
        --env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin \
        --env LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib:/usr/lib64:/usr/lib \
        ${run_in_cont_term} \
        ${run_in_cont_colorterm} \
        --env JINX_PARALLELISM="$parallelism" \
        --env JINX_CONFIG_FILE=/base_dir/Jinxfile \
        --env JINX_SOURCE_DIR=/base_dir \
        ${nochown_so} \
        ${container_pkgs_native_mount:+"${container_pkgs_native_mount}"} \
        ${sysroot_native_mount:+"${sysroot_native_mount}"} \
        -m"${base_dir}":/base_dir${container_base_dir_ro} \
        ${shadow_git_dir_base:+"${shadow_git_dir_base}"} \
        -m"${base_dir}"/sources:/base_dir/sources${container_sources_ro} \
        -m"${build_dir}":/build_dir \
        ${shadow_git_dir_build:+"${shadow_git_dir_build}"} \
        ${unshare_net_flag} \
        --workdir / \
        -- \
        /bin/bash -c "cd /build_dir && /bin/bash /base_dir/jinx $run_in_cont_argvar"

    rm -rf "${imgroot}/sysroot" "${imgroot}/base_dir" "${imgroot}/sources" "${imgroot}/build_dir"
}

destroy_container() {
    rm -rf "${container_pkgs}" "${sysroot_dir}"
}

do_hg_fetch() {
    hg clone "${hg_url}" "${base_dir}"/sources/${name}
    ( cd "${base_dir}"/sources/${name} && hg up "${tag}" )
}

do_git_fetch() {
    if [ -z "${commit}" ]; then
        die "* error: Git commit not specified"
    fi

    if ! ( echo "${commit}" | grep -qE '^[0-9a-f]{40}$' ); then
        die "* error: Invalid commit hash"
    fi

    if [ "${shallow}" = "no" ]; then
        git clone "${git_url}" "${base_dir}"/sources/${name}
        git -C "${base_dir}"/sources/${name} -c advice.detachedHead=false checkout "${commit}"
    else
        git clone "${git_url}" -c advice.detachedHead=false --revision="${commit}" --depth=1 "${base_dir}"/sources/${name}
    fi
}

do_tarball_fetch() {
    tarball_path="${base_dir}"/sources/"$(basename "${tarball_url}")"

    if ! [ -f "$tarball_path" ]; then
        make_temp
        download_path="${tmp}"

        curl -L -o "${download_path}" "${tarball_url}"
        mv "${download_path}" "${tarball_path}"
    fi

    checksum_verified=no

    if ! [ -z "${tarball_sha256}" ]; then
        actual_sha256="$(sha256sum "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_sha256} = ${tarball_sha256} ]; then
            die "* error: Failed to verify SHA256 for ${name}.
  Expected '${tarball_sha256}';
  got '${actual_sha256}'."
        fi
        checksum_verified=yes
    fi
    if ! [ -z "${tarball_sha512}" ]; then
        actual_sha512="$(sha512sum "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_sha512} = ${tarball_sha512} ]; then
            die "* error: Failed to verify SHA512 for ${name}.
  Expected '${tarball_sha512}';
  got '${actual_sha512}'."
        fi
        checksum_verified=yes
    fi
    if ! [ -z "${tarball_blake2b}" ]; then
        actual_blake2b="$(b2sum "${tarball_path}" | awk '{print $1;}')"
        if ! [ ${actual_blake2b} = ${tarball_blake2b} ]; then
            die "* error: Failed to verify BLAKE2B for ${name}.
  Expected '${tarball_blake2b}';
  got '${actual_blake2b}'."
        fi
        checksum_verified=yes
    fi

    if [ "${checksum_verified}" = "no" ]; then
        die "* error: No checksum method specified for ${name}"
    fi

    make_temp -d
    extract_dir="${tmp}"

    ( cd "${extract_dir}" && tar -xf "${tarball_path}" )

    mv "${extract_dir}"/* "${base_dir}"/sources/${name} >/dev/null 2>&1 || (
        make_dir "${base_dir}"/sources/${name}
        mv "${extract_dir}"/* "${base_dir}"/sources/${name}/
    )

    rm -rf "${extract_dir}" "${tarball_path}"
}

get_real_source_dir() {
    if [ -z "${source_dir}" ]; then
        source_dir="${base_dir}"/sources/${name}
    else
        source_dir="${base_dir}"/"${source_dir}"
        is_local_package=true
    fi
}

cont_fetch() {
    make_dir "${base_dir}"/sources

    source_source_recipe $1

    get_real_source_dir

    if ! [ -z "${git_url}" ]; then
        do_git_fetch
    elif ! [ -z "${hg_url}" ]; then
        do_hg_fetch
    elif ! [ -z "${tarball_url}" ]; then
        do_tarball_fetch
    fi
}

default_recipe_steps() {
    prepare() {
        true
    }

    configure() {
        true
    }

    build() {
        true
    }

    package() {
        true
    }
}

source_source_recipe() {
    if [ -f "${base_dir}"/source-recipes/$1 ]; then
        . "${base_dir}"/source-recipes/$1
    elif [ -f "${base_dir}"/recipes/$1 ]; then
        . "${base_dir}"/recipes/$1

        unset deps
        unset builddeps
        unset hostrundeps
        imagedeps="${source_imagedeps}"
        hostdeps="${source_hostdeps}"
        deps="${source_deps}"
        allow_network="${source_allow_network}"
    else
        die "* could not find source recipe '$1'"
    fi
}

cont_patch() {
    source_source_recipe $1

    get_real_source_dir

    make_temp
    patch_trash="${tmp}"

    cd "${source_dir}"

    needs_match_timestamps=no
    rm -rf "${base_dir}"/sources/${name}-clean
    if [ -d "${base_dir}"/patches/${name} ]; then
        for patch in "${base_dir}"/patches/${name}/*; do
            [ "${patch}" = "${base_dir}/patches/${name}/*" ] && break
            [ "${patch}" = "${base_dir}"/patches/${name}/jinx-working-patch.patch ] && continue

            if ! [ -d "${base_dir}"/sources/${name}-clean ]; then
                cp -rp "${source_dir}" "${base_dir}"/sources/${name}-clean
                needs_match_timestamps=yes
            fi

            patch --no-backup-if-mismatch -p1 -r "${patch_trash}" < "${patch}"
        done

        if [ "${needs_match_timestamps}" = yes ]; then
            # make sure timestamps match
            for f in $(diff -rq --no-dereference "${base_dir}"/sources/${name}-clean "${source_dir}" | sed '/^Only in/d;s/^Files //g;s/ and.*$//g'); do
                touch --reference="$f" "$(echo "$f" | sed "s|sources/${name}-clean|sources/${name}|g")"
            done
            rm -rf "${base_dir}"/sources/${name}-clean
        fi
    fi

    cp -rp "${source_dir}" "${base_dir}"/sources/${name}-clean

    if [ -f "${base_dir}"/patches/${name}/jinx-working-patch.patch ]; then
        patch --no-backup-if-mismatch -p1 -r "${patch_trash}" < "${base_dir}"/patches/${name}/jinx-working-patch.patch

        # make sure timestamps match
        for f in $(diff -rq --no-dereference "${base_dir}"/sources/${name}-clean "${source_dir}" | sed '/^Only in/d;s/^Files //g;s/ and.*$//g'); do
            touch --reference="$f" "$(echo "$f" | sed "s|sources/${name}-clean|sources/${name}|g")"
        done
    fi

    cp -rp "${source_dir}" "${base_dir}"/sources/${name}-workdir

    cd "${base_dir}"

    touch "${base_dir}"/sources/${name}.patched
}

do_prepare() {
    default_recipe_steps

    source_source_recipe $1

    get_real_source_dir

    [ -f "${base_dir}"/sources/${name}.prepared ] && return

    sysroot_dir="/sysroot"

    cd "${source_dir}"
    [ "${is_local_package}" = true ] || container_base_dir_ro=":ro"
    prepare
    container_base_dir_ro=""
    cd "${base_dir}"

    touch "${base_dir}"/sources/${name}.prepared
}

do_configure_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    make_dir "${build_dir}"/host-builds/${name}

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/host-builds/${name}
    configure
    cd "${base_dir}"
}

do_build_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    make_dir "${build_dir}"/host-builds/${name}

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/host-builds/${name}
    build
    cd "${base_dir}"
}

do_package_host() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/host-recipes/$1

    dest_dir="${build_dir}"/host-pkgs/${name}

    rm -rf "${dest_dir}"
    make_dir "${dest_dir}"

    if ! [ -z "${from_source}" ]; then
        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr/local"
    sysroot_dir="/sysroot"

    make_dir "${dest_dir}${prefix}"

    cd "${build_dir}"/host-builds/${name}
    package

    # Remove libtool files
    for i in $(find "${dest_dir}${prefix}" -name "*.la"); do
        rm -rvf $i
    done

    cd "${base_dir}"
}

do_configure() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    make_dir "${build_dir}"/builds/${name}

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/builds/${name}
    configure
    cd "${base_dir}"
}

do_build() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    make_dir "${build_dir}"/builds/${name}

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    cd "${build_dir}"/builds/${name}
    build
    cd "${base_dir}"
}

do_package() {
    default_recipe_steps

    unset from_source
    . "${base_dir}"/recipes/$1

    dest_dir="${build_dir}"/pkgs/${name}

    rm -rf "${dest_dir}"
    make_dir "${dest_dir}"

    if ! [ -z "${from_source}" ] || ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
            source_dir="$(unset source_dir && source_source_recipe ${from_source} && echo "$source_dir")"
        else
            from_source=${name}
        fi

        if [ -z "${source_dir}" ]; then
            source_dir="${base_dir}"/sources/${from_source}
        else
            source_dir="${base_dir}"/"${source_dir}"
        fi
    fi

    prefix="/usr"
    sysroot_dir="/sysroot"

    make_dir "${dest_dir}${prefix}"

    cd "${build_dir}"/builds/${name}
    package

    # Remove libtool files
    for i in $(find "${dest_dir}${prefix}" -name "*.la"); do
        rm -rvf $i
    done

    xbps_deps=""
    for dep in ${deps}; do
        bootstrap_pkg=$(unset bootstrap_pkg && . "${base_dir}"/recipes/${dep} && echo "${bootstrap_pkg}")
        if [ "${bootstrap_pkg}" = "yes" ]; then
            continue
        fi

        xbps_deps="${xbps_deps} ${dep}>=0.0"
    done

    cd "${build_dir}"/pkgs
        XBPS_ARCH=invalid \
        XBPS_TARGET_ARCH="${JINX_ARCH}" \
    "$JINX_CACHE_DIR"/xbps-bin/xbps-create \
        -A $JINX_ARCH \
        -s ${name} \
        -n ${name}-${version}_${revision} \
        -D "${xbps_deps}" \
        "${dest_dir}"

    rm -rf "${dest_dir}"

    cd "${base_dir}"
}

precont_fetch() {
    source_source_recipe $1

    get_real_source_dir

    [ -d "${source_dir}" ] && return

    cross_compile=yes
    allow_network="yes"
    prepare_container
    run_in_container internal-cont-fetch $1
    destroy_container
}

precont_patch() {
    [ -f "${base_dir}"/sources/$1.patched ] && return

    cross_compile=yes
    prepare_container
    run_in_container internal-cont-patch $1
    destroy_container
}

do_source() {
    source_source_recipe $1

    get_real_source_dir

    "${script}" internal-precont-fetch $1

    "${script}" internal-precont-patch $1

    [ -f "${base_dir}"/sources/$1.prepared ] && return

    cross_compile=yes
    prepare_container
    run_in_container internal-prepare $1
    destroy_container
}

do_cmd_rebuild() {
    rm -rf "${build_dir}"/builds/"$1"

    do_pkg "$1"
}

do_cmd_host_rebuild() {
    rm -rf "${build_dir}"/host-builds/"$1"

    do_host_pkg "$1"
}

do_cmd_prepare() {
    source_source_recipe $1

    [ -f "${base_dir}"/sources/$1.patched ] || die "cannot regenerate non-built package"

    get_real_source_dir

    make_temp
    patch_file="${tmp}"

    if ! [ "${is_local_package}" = true ]; then
        cd "${base_dir}"/sources

        # exclude version control dirs
        make_temp -d
        vc_dir_clean="${tmp}"
        rm -rf "${vc_dir_clean}"
        make_temp -d
        vc_dir_workdir="${tmp}"
        rm -rf "${vc_dir_workdir}"

        if ! [ -z "${git_url}" ]; then
            mv $1-clean/.git "${vc_dir_clean}"
            mv $1-workdir/.git "${vc_dir_workdir}"
        elif ! [ -z "${hg_url}" ]; then
            mv $1-clean/.hg "${vc_dir_clean}"
            mv $1-workdir/.hg "${vc_dir_workdir}"
        fi

        diff -urN --no-dereference $1-clean $1-workdir >"${patch_file}" || true

        # remove timestamps
        sed -Ei 's/\t2[0-9]{3}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}\.[0-9]{9} [+-][0-9]{4}//g' "${patch_file}"

        if ! [ -z "${git_url}" ]; then
            mv "${vc_dir_clean}" $1-clean/.git
            mv "${vc_dir_workdir}" $1-workdir/.git
        elif ! [ -z "${hg_url}" ]; then
            mv "${vc_dir_clean}" $1-clean/.hg
            mv "${vc_dir_workdir}" $1-workdir/.hg
        fi

        if [ -s "${patch_file}" ]; then
            make_dir "${base_dir}"/patches/$1
            mv "${patch_file}" "${base_dir}"/patches/$1/jinx-working-patch.patch
        fi

        cd "${base_dir}"

        rm -rf "${source_dir}"
        cp -rp "${base_dir}"/sources/$1-workdir "${source_dir}"
    fi

    rm -rf "${base_dir}"/sources/$1.prepared

    cross_compile=yes
    prepare_container
    run_in_container internal-prepare $1
    destroy_container
}

do_host_pkg() {
    unset from_source
    . "${base_dir}"/host-recipes/$1

    echo "* building host package: $name"

    cross_compile=yes
    prepare_container

    if ! [ -z "${from_source}" ]; then
        from_source="$(. "${base_dir}"/host-recipes/$1 && echo "$from_source")"
        [ -f "${base_dir}"/sources/${from_source}.prepared ] || \
            "${script}" internal-source "${from_source}"
    fi

    container_sources_ro=":ro"
    if ! [ -d "${build_dir}"/host-builds/$1 ]; then
        run_in_container internal-configure-host $1
    fi
    run_in_container internal-build-host $1
    rm -rf "${build_dir}"/host-pkgs/$1
    run_in_container internal-package-host $1
    unset container_sources_ro

    destroy_container

    if [ "$JINX_CLEAN_WORKDIRS" = "yes" ]; then
        (
        unset from_source
        unset clean_workdirs
        . "${base_dir}"/host-recipes/$1

        if ! [ "$clean_workdirs" = "no" ]; then
            rm -rf "${build_dir}"/host-builds/$1

            if [ -z "${from_source}" ]; then
                source_source_recipe $1
            else
                source_source_recipe ${from_source}
            fi

            rm -rf \
                "${base_dir}"/sources/"${name}" \
                "${base_dir}"/sources/"${name}"-clean \
                "${base_dir}"/sources/"${name}"-workdir \
                "${base_dir}"/sources/"${name}".patched \
                "${base_dir}"/sources/"${name}".prepared
        fi
        )
    fi
}

do_pkg() {
    unset from_source
    . "${base_dir}"/recipes/$1

    echo "* building package: $name"

    if ! [ -z "${from_source}" ]; then
        [ -f "${base_dir}"/sources/${from_source}.prepared ] || \
            "${script}" internal-source "${from_source}"

        version=$(unset version && source_source_recipe ${from_source} && echo "$version")
    fi

    prepare_container

    if ! [ -z "${tarball_url}" ] || ! [ -z "${git_url}" ] || ! [ -z "${hg_url}" ] || ! [ -z "${source_dir}" ]; then
        "${script}" internal-source "${name}"
    fi

    container_sources_ro=":ro"
    if ! [ -d "${build_dir}"/builds/$1 ]; then
        run_in_container internal-configure $1
    fi
    run_in_container internal-build $1
    rm -rf "${build_dir}"/pkgs/$1
    run_in_container internal-package $1
    unset container_sources_ro

    destroy_container

        XBPS_ARCH=invalid \
        XBPS_TARGET_ARCH="${JINX_ARCH}" \
    "$JINX_CACHE_DIR"/xbps-bin/xbps-rindex \
        -a "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps \
        -f

    if [ "$JINX_CLEAN_WORKDIRS" = "yes" ]; then
        (
        unset from_source
        unset clean_workdirs
        . "${base_dir}"/recipes/$1

        if ! [ "$clean_workdirs" = "no" ]; then
            rm -rf "${build_dir}"/builds/$1

            if [ -z "${from_source}" ]; then
                source_source_recipe $1
            else
                source_source_recipe ${from_source}
            fi

            rm -rf \
                "${base_dir}"/sources/"${name}" \
                "${base_dir}"/sources/"${name}"-clean \
                "${base_dir}"/sources/"${name}"-workdir \
                "${base_dir}"/sources/"${name}".patched \
                "${base_dir}"/sources/"${name}".prepared
        fi
        )
    fi
}

cmd_host_build() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/host-recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-host-pkg "${pkg}"
        done
    done
}

cmd_build() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-pkg "${pkg}"
        done
    done
}

cmd_build_if_needed() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            (
                set -e
                unset version
                unset from_source
                . "${base_dir}"/recipes/${pkg}
                if ! [ -z "${from_source}" ]; then
                    version=$(unset version && source_source_recipe ${from_source} && echo "$version")
                fi

                [ -f "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps ]
            ) && continue

            "${script}" internal-do-pkg "${pkg}"
        done
    done
}

cmd_prepare() {
    for i in "$@"; do
        "${script}" internal-do-prepare "$i"
    done
}

cmd_host_rebuild() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/host-recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-host-rebuild "${pkg}"
        done
    done
}

cmd_rebuild() {
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            "${script}" internal-do-rebuild "${pkg}"
        done
    done
}

cmd_install() {
    force_install=""
    if [ "$1" = "-f" ]; then
        force_install="$1"
        shift 1
    fi
    sysroot="$1"
    shift 1
    mkdir -m 755 -p "${sysroot}"

    pkgs_to_install=""
    for ppkg in "$@"; do
        for pkg in $(eval '(' cd "'${base_dir}'"/recipes '&&' echo "${ppkg}" ')' ); do
            bootstrap_pkg=$(unset bootstrap_pkg && . "${base_dir}"/recipes/${pkg} && echo "${bootstrap_pkg}")
            if [ "${bootstrap_pkg}" = "yes" ]; then
                continue
            fi

            pkgs_to_install="${pkgs_to_install} ${pkg}"
        done
    done

    files_to_ignore='\.keep
\.plist
/INSTALL
/REMOVE'

    make_temp
    all_files="${tmp}"

    for pkg in ${pkgs_to_install}; do
        echo "* installing ${pkg}..."

        unset name
        unset version
        unset revision
        unset from_source
        . "${base_dir}"/recipes/${pkg}

        if ! [ -z "${from_source}" ]; then
            version=$(unset version && source_source_recipe ${from_source} && echo "$version")
        fi

        if ! [ -f "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps ]; then
            die "* package '${name}' not built"
        fi

        # xbps seems to only install the package every second time when reinstalling.
        # Remove the package to be sure it gets reinstalled.
        if ! [ -z "${force_install}" ]; then
            XBPS_ARCH=invalid \
            XBPS_TARGET_ARCH="${JINX_ARCH}" \
                "$JINX_CACHE_DIR"/xbps-bin/xbps-remove -Ffy -r "${sysroot}" ${pkg} >/dev/null 2>&1 || true
        fi

        XBPS_ARCH=invalid \
        XBPS_TARGET_ARCH="${JINX_ARCH}" \
            "$JINX_CACHE_DIR"/xbps-bin/xbps-install -y $force_install -r "${sysroot}" -R "${build_dir}"/pkgs ${pkg} >/dev/null 2>&1

        tar -tf "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps | ( grep -v "${files_to_ignore}" || true ) >>"${all_files}"
    done

    echo "* checking for conflicts..."

    make_temp
    all_files_sorted="${tmp}"

    make_temp
    all_files_uniq="${tmp}"

    sort <"${all_files}" >"${all_files_sorted}"
    uniq <"${all_files_sorted}" >"${all_files_uniq}"

    dup_elements="$(comm -23 "${all_files_sorted}" "${all_files_uniq}" | uniq)"

    if ! [ -z "${dup_elements}" ]; then
        echo "* error: duplicate files were found."
        for elem in ${dup_elements}; do
            echo "  file path: ${elem}"
            printf "  in packages:"
            for pkg in ${pkgs_to_install}; do
                unset name
                unset version
                unset revision
                unset from_source
                . "${base_dir}"/recipes/${pkg}

                if ! [ -z "${from_source}" ]; then
                    version=$(unset version && source_source_recipe ${from_source} && echo "$version")
                fi

                if tar -tf "${build_dir}"/pkgs/${name}-${version}_${revision}.${JINX_ARCH}.xbps | ( grep -v "${files_to_ignore}" || true ) | grep -q "${elem}"; then
                    printf " ${pkg}"
                fi
            done
            printf "\n"
        done
        exit 1
    fi
}

rebuild_b2sum() {
    cat <<'EOF' >"$JINX_CACHE_DIR/b2sum.c"
// This blake2b implementation comes from the GNU coreutils project.
// https://github.com/coreutils/coreutils/blob/master/src/blake2/blake2b-ref.c

#include <stdbool.h>
#include <stdint.h>
#include <stddef.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define BLAKE2B_OUT_BYTES 64
#define BLAKE2B_BLOCK_BYTES 128
#define BLAKE2B_KEY_BYTES 64
#define BLAKE2B_SALT_BYTES 16
#define BLAKE2B_PERSONAL_BYTES 16

static const uint64_t blake2b_iv[8] = {
    0x6a09e667f3bcc908,
    0xbb67ae8584caa73b,
    0x3c6ef372fe94f82b,
    0xa54ff53a5f1d36f1,
    0x510e527fade682d1,
    0x9b05688c2b3e6c1f,
    0x1f83d9abfb41bd6b,
    0x5be0cd19137e2179,
};

static const uint8_t blake2b_sigma[12][16] = {
    {  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
    { 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
    { 11,  8, 12,  0,  5,  2, 15, 13, 10, 14,  3,  6,  7,  1,  9,  4 },
    {  7,  9,  3,  1, 13, 12, 11, 14,  2,  6,  5, 10,  4,  0, 15,  8 },
    {  9,  0,  5,  7,  2,  4, 10, 15, 14,  1, 11, 12,  6,  8,  3, 13 },
    {  2, 12,  6, 10,  0, 11,  8,  3,  4, 13,  7,  5, 15, 14,  1,  9 },
    { 12,  5,  1, 15, 14, 13,  4, 10,  0,  7,  6,  3,  9,  2,  8, 11 },
    { 13, 11,  7, 14, 12,  1,  3,  9,  5,  0, 15,  4,  8,  6,  2, 10 },
    {  6, 15, 14,  9, 11,  3,  0,  8, 12,  2, 13,  7,  1,  4, 10,  5 },
    { 10,  2,  8,  4,  7,  6,  1,  5, 15, 11,  9, 14,  3, 12, 13,  0 },
    {  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15 },
    { 14, 10,  4,  8,  9, 15, 13,  6,  1, 12,  0,  2, 11,  7,  5,  3 },
};

struct blake2b_state {
    uint64_t h[8];
    uint64_t t[2];
    uint64_t f[2];
    uint8_t buf[BLAKE2B_BLOCK_BYTES];
    size_t buf_len;
    uint8_t last_node;
};

struct blake2b_param {
    uint8_t digest_length;
    uint8_t key_length;
    uint8_t fan_out;
    uint8_t depth;
    uint32_t leaf_length;
    uint32_t node_offset;
    uint32_t xof_length;
    uint8_t node_depth;
    uint8_t inner_length;
    uint8_t reserved[14];
    uint8_t salt[BLAKE2B_SALT_BYTES];
    uint8_t personal[BLAKE2B_PERSONAL_BYTES];
} __attribute__((packed));

static void blake2b_increment_counter(struct blake2b_state *state, uint64_t inc) {
    state->t[0] += inc;
    state->t[1] += state->t[0] < inc;
}

static inline uint64_t rotr64(uint64_t w, unsigned c) {
    return (w >> c) | (w << (64 - c));
}

#define G(r, i, a, b, c, d) do { \
        a = a + b + m[blake2b_sigma[r][2 * i + 0]]; \
        d = rotr64(d ^ a, 32); \
        c = c + d; \
        b = rotr64(b ^ c, 24); \
        a = a + b + m[blake2b_sigma[r][2 * i + 1]]; \
        d = rotr64(d ^ a, 16); \
        c = c + d; \
        b = rotr64(b ^ c, 63); \
    } while (0)

#define ROUND(r) do { \
        G(r, 0, v[0], v[4], v[8], v[12]); \
        G(r, 1, v[1], v[5], v[9], v[13]); \
        G(r, 2, v[2], v[6], v[10], v[14]); \
        G(r, 3, v[3], v[7], v[11], v[15]); \
        G(r, 4, v[0], v[5], v[10], v[15]); \
        G(r, 5, v[1], v[6], v[11], v[12]); \
        G(r, 6, v[2], v[7], v[8], v[13]); \
        G(r, 7, v[3], v[4], v[9], v[14]); \
    } while (0)

static void blake2b_compress(struct blake2b_state *state, const uint8_t block[static BLAKE2B_BLOCK_BYTES]) {
    uint64_t m[16];
    uint64_t v[16];

    for (int i = 0; i < 16; i++) {
        m[i] = *(uint64_t *)(block + i * sizeof(m[i]));
    }

    for (int i = 0; i < 8; i++) {
        v[i] = state->h[i];
    }

    v[8] = blake2b_iv[0];
    v[9] = blake2b_iv[1];
    v[10] = blake2b_iv[2];
    v[11] = blake2b_iv[3];
    v[12] = blake2b_iv[4] ^ state->t[0];
    v[13] = blake2b_iv[5] ^ state->t[1];
    v[14] = blake2b_iv[6] ^ state->f[0];
    v[15] = blake2b_iv[7] ^ state->f[1];

    ROUND(0);
    ROUND(1);
    ROUND(2);
    ROUND(3);
    ROUND(4);
    ROUND(5);
    ROUND(6);
    ROUND(7);
    ROUND(8);
    ROUND(9);
    ROUND(10);
    ROUND(11);

    for (int i = 0; i < 8; i++) {
        state->h[i] = state->h[i] ^ v[i] ^ v[i + 8];
    }
}

#undef G
#undef ROUND

static void blake2b_init(struct blake2b_state *state) {
    struct blake2b_param param;
    memset(&param, 0, sizeof(struct blake2b_param));

    param.digest_length = BLAKE2B_OUT_BYTES;
    param.fan_out = 1;
    param.depth = 1;

    memset(state, 0, sizeof(struct blake2b_state));

    for (int i = 0; i < 8; i++) {
        state->h[i] = blake2b_iv[i];
    }

    for (int i = 0; i < 8; i++) {
        state->h[i] ^= *(uint64_t *)((void *)&param + sizeof(state->h[i]) * i);
    }
}

static void blake2b_update(struct blake2b_state *state, const void *in, size_t in_len) {
    if (in_len == 0) {
        return;
    }

    size_t left = state->buf_len;
    size_t fill = BLAKE2B_BLOCK_BYTES - left;

    if (in_len > fill) {
        state->buf_len = 0;

        memcpy(state->buf + left, in, fill);
        blake2b_increment_counter(state, BLAKE2B_BLOCK_BYTES);
        blake2b_compress(state, state->buf);

        in += fill;
        in_len -= fill;

        while (in_len > BLAKE2B_BLOCK_BYTES) {
            blake2b_increment_counter(state, BLAKE2B_BLOCK_BYTES);
            blake2b_compress(state, in);

            in += fill;
            in_len -= fill;
        }
    }

    memcpy(state->buf + state->buf_len, in, in_len);
    state->buf_len += in_len;
}

static void blake2b_final(struct blake2b_state *state, void *out) {
    uint8_t buffer[BLAKE2B_OUT_BYTES] = {0};

    blake2b_increment_counter(state, state->buf_len);
    state->f[0] = (uint64_t)-1;
    memset(state->buf + state->buf_len, 0, BLAKE2B_BLOCK_BYTES - state->buf_len);
    blake2b_compress(state, state->buf);

    for (int i = 0; i < 8; i++) {
        *(uint64_t *)(buffer + sizeof(state->h[i]) * i) = state->h[i];
    }

    memcpy(out, buffer, BLAKE2B_OUT_BYTES);
    memset(buffer, 0, sizeof(buffer));
}

static void blake2b(void *out, const void *in, size_t in_len) {
    struct blake2b_state state = {0};

    blake2b_init(&state);
    blake2b_update(&state, in, in_len);
    blake2b_final(&state, out);
}

int main(int argc, char *argv[]) {
    if (argc < 2) {
        return EXIT_FAILURE;
    }

    FILE *f = fopen(argv[1], "r");
    if (f == NULL) {
        return EXIT_FAILURE;
    }

    fseek(f, 0, SEEK_END);
    size_t f_size = ftell(f);
    rewind(f);

    void *mem = malloc(f_size);
    if (mem == NULL) {
        return EXIT_FAILURE;
    }

    if (fread(mem, f_size, 1, f) != 1) {
        return EXIT_FAILURE;
    }

    uint8_t out_buf[BLAKE2B_OUT_BYTES];
    blake2b(out_buf, mem, f_size);

    for (size_t i = 0; i < BLAKE2B_OUT_BYTES; i++) {
        printf("%02x", out_buf[i]);
    }

    printf("  %s\n", argv[1]);
}
EOF
    cc -O2 -pipe -fno-strict-aliasing -Wall -Wextra "$JINX_CACHE_DIR/b2sum.c" -o "$JINX_CACHE_DIR/b2sum"
}

rebuild_rbrt() {
    cat <<'EOF' >"$JINX_CACHE_DIR/rbrt.c"
// Written by 48cf (iretq@riseup.net)
// Inspired heavily by https://github.com/managarm/cbuildrt/

#define _GNU_SOURCE

#include <stddef.h>
#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <limits.h>
#include <errno.h>
#include <unistd.h>
#include <fcntl.h>
#include <sched.h>
#include <sys/mount.h>
#include <sys/wait.h>

#define STRINGIFY(x) #x
#define TOSTRING(x) STRINGIFY(x)

int main(int argc, char *argv[]) {
    int ok = 1;
    const char *err_msg = "";

    char *rootfs = NULL;
    char **mounts = NULL;
    char **envs = NULL;
    char **process_args = NULL;

    int mount_count = 0;
    int mounts_size = 0;

    int env_count = 0;
    int envs_size = 0;

    bool rw_root = false;
    bool unshare_net = false;

    int uid = -1, gid = -1;
    int euid = geteuid();
    int egid = getegid();

    int setgroups_fd = -1;
    int uid_map_fd = -1;
    int gid_map_fd = -1;

    char *workdir = "/";

    for (int i = 1; i < argc; ) {
        if (strcmp(argv[i], "--workdir") == 0) {
            workdir = argv[i + 1];
            i += 2;
        } else if (strcmp(argv[i], "-r") == 0 || strcmp(argv[i], "--root") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            rootfs = argv[i + 1];
            i += 2;

            if (i < argc - 1 && strcmp(argv[i], "rw") == 0) {
                rw_root = true;
                i++;
            }
        } else if (strcmp(argv[i], "-u") == 0 || strcmp(argv[i], "--uid") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (sscanf(argv[i + 1], "%d", &uid) != 1) {
                fprintf(stderr, "%s: '%s' is not a valid user ID\n", argv[0], argv[i + 1]);
                goto cleanup;
            }

            i += 2;
        } else if (strcmp(argv[i], "-g") == 0 || strcmp(argv[i], "--gid") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (sscanf(argv[i + 1], "%d", &gid) != 1) {
                fprintf(stderr, "%s: '%s' is not a valid group ID\n", argv[0], argv[i + 1]);
                goto cleanup;
            }

            i += 2;
        } else if (strncmp(argv[i], "-m", 2) == 0) {
            if (mount_count == mounts_size) {
                mounts_size = mounts_size == 0 ? 16 : mounts_size * 2;
                char **tmp_mounts = realloc(mounts, sizeof(char *) * mounts_size);
                if (tmp_mounts == NULL) {
                    fprintf(stderr, "%s: failed to allocate mounts array\n", argv[0]);
                    goto cleanup;
                }
                mounts = tmp_mounts;
            }

            char *target = argv[i] + 2;
            while (*target && *target != ':') {
                target++;
            }

            if (!*target) {
                fprintf(stderr, "%s: mount points need to be provided in the 'source:target' format\n", argv[0]);
                goto cleanup;
            }

            mounts[mount_count++] = argv[i] + 2;
            i += 1;
        } else if (strcmp(argv[i], "-e") == 0 || strcmp(argv[i], "--env") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: '%s' requires a value\n", argv[0], argv[i]);
                goto cleanup;
            }

            if (env_count == envs_size) {
                envs_size = envs_size == 0 ? 16 : envs_size * 2;
                char **tmp_envs = realloc(envs, sizeof(char *) * envs_size);
                if (tmp_envs == NULL) {
                    fprintf(stderr, "%s: failed to allocate environment variables array\n", argv[0]);
                    goto cleanup;
                }
                envs = tmp_envs;
            }

            char *value = argv[i + 1];
            while (*value && *value != '=') {
                value++;
            }

            if (!*value) {
                fprintf(stderr, "%s: environment variables need to be provided in the 'key=value' format\n", argv[0]);
                goto cleanup;
            }

            envs[env_count++] = argv[i + 1];
            i += 2;
        } else if (strcmp(argv[i], "-n") == 0 || strcmp(argv[i], "--net") == 0) {
            unshare_net = true;
            i += 1;
        } else if (strcmp(argv[i], "--") == 0) {
            if (i == argc - 1) {
                fprintf(stderr, "%s: at least one trailing argument is required\n", argv[0]);
                goto cleanup;
            }

            process_args = &argv[i + 1];
            break;
        } else {
            fprintf(stderr, "%s: unrecognized option '%s'\n", argv[0], argv[i]);
            goto cleanup;
        }
    }

    if (rootfs == NULL) {
        fprintf(stderr, "%s: root file system path is required\n", argv[0]);
        goto cleanup;
    }

    if (process_args == NULL) {
        fprintf(stderr, "%s: process arguments are requires\n", argv[0]);
        goto cleanup;
    }

    if (uid == -1 || gid == -1) {
        fprintf(stderr, "%s: user and group IDs are both required\n", argv[0]);
        goto cleanup;
    }

    if (unshare(CLONE_NEWUSER | CLONE_NEWPID) < 0) {
        err_msg = "unshare() failure at line " TOSTRING(__LINE__);
        goto errno_error;
    }

    char uid_map[64], gid_map[64];

    int uid_map_len = snprintf(uid_map, 64, "%d %d 1", uid, euid);
    int gid_map_len = snprintf(gid_map, 64, "%d %d 1", gid, egid);

    setgroups_fd = open("/proc/self/setgroups", O_RDWR);
    if (setgroups_fd < 0 || write(setgroups_fd, "deny", 4) < 0) {
        err_msg = "failed to open or write to /proc/self/setgroups at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(setgroups_fd);
    setgroups_fd = -1;

    uid_map_fd = open("/proc/self/uid_map", O_RDWR);
    if (uid_map_fd < 0 || write(uid_map_fd, uid_map, uid_map_len) < 0) {
        err_msg = "failed to open or write to /proc/self/uid_map at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(uid_map_fd);
    uid_map_fd = -1;

    gid_map_fd = open("/proc/self/gid_map", O_RDWR);
    if (gid_map_fd < 0 || write(gid_map_fd, gid_map, gid_map_len) < 0) {
        err_msg = "failed to open or write to /proc/self/gid_map at line " TOSTRING(__LINE__);
        goto errno_error;
    }
    close(gid_map_fd);
    gid_map_fd = -1;

    if (setuid(uid) < 0 || setgid(gid) < 0) {
        err_msg = "setuid()/setgid() failure at line " TOSTRING(__LINE__);
        goto errno_error;
    }

    int child_pid = fork();
    if (child_pid == 0) {
        if (unshare(CLONE_NEWNS) < 0) {
            err_msg = "unshare() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (mount(rootfs, rootfs, NULL, MS_BIND, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        int root_flags = MS_REMOUNT | MS_BIND | MS_NOSUID | MS_NODEV;

        if (!rw_root) {
            root_flags |= MS_RDONLY;
        }

        if (mount(rootfs, rootfs, NULL, root_flags, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        char target_path[PATH_MAX];

        snprintf(target_path, PATH_MAX, "%s/etc/resolv.conf", rootfs);
        if (mount("/etc/resolv.conf", target_path, NULL, MS_BIND, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/dev", rootfs);
        if (mount("/dev", target_path, NULL, MS_REC | MS_BIND | MS_SLAVE, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/sys", rootfs);
        if (mount("/sys", target_path, NULL, MS_REC | MS_BIND | MS_SLAVE, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/run", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/tmp", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/var/tmp", rootfs);
        if (mount(NULL, target_path, "tmpfs", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        snprintf(target_path, PATH_MAX, "%s/proc", rootfs);
        if (mount(NULL, target_path, "proc", 0, NULL) < 0) {
            err_msg = "mount() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        for (int i = 0; i < mount_count; i++) {
            char *source = mounts[i];
            char *target = source;

            while (*target && *target != ':') {
                target++;
            }

            *target++ = 0;

            char *read_only = target;

            while (*read_only && *read_only != ':') {
                read_only++;
            }

            bool ro = false;
            if (*read_only == ':') {
                *read_only++ = 0;
                ro = strcmp(read_only, "ro") == 0;
            }

            snprintf(target_path, PATH_MAX, "%s%s", rootfs, target);
            if (mount(source, target_path, NULL, MS_BIND | (ro ? MS_RDONLY : 0), NULL) < 0) {
                err_msg = "mount() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }
            if (ro) {
                if (mount(source, target_path, NULL, MS_REMOUNT | MS_BIND | MS_RDONLY, NULL) < 0) {
                    err_msg = "mount() failure at line " TOSTRING(__LINE__);
                    goto errno_error;
                }
            }
        }

        if (unshare_net && unshare(CLONE_NEWNET) < 0) {
            err_msg = "unshare() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (chroot(rootfs) < 0) {
            err_msg = "chroot() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        if (chdir(workdir) < 0) {
            err_msg = "chdir() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        int child = fork();
        if (child == 0) {
            clearenv();

            setenv("HOME", "/root", 1);
            setenv("LANG", "C", 1);
            setenv("PATH", "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin", 1);

            for (int i = 0; i < env_count; i++) {
                char *key = envs[i];
                char *value = key;

                while (*value && *value != '=') {
                    value++;
                }

                *value++ = 0;
                setenv(key, value, 1);
            }

            if (execvp(process_args[0], process_args) < 0) {
                err_msg = "execvp() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }

            __builtin_unreachable();
        } else {
            int exit_code = -1;
            if (waitpid(child, &exit_code, 0) < 0) {
                err_msg = "waitpid() failure at line " TOSTRING(__LINE__);
                goto errno_error;
            }

            ok = WEXITSTATUS(exit_code);
            goto cleanup;
        }

        __builtin_unreachable();
    } else {
        int exit_code = -1;
        if (waitpid(child_pid, &exit_code, 0) < 0) {
            err_msg = "waitpid() failure at line " TOSTRING(__LINE__);
            goto errno_error;
        }

        ok = WEXITSTATUS(exit_code);
        goto cleanup;
    }

errno_error:
    fprintf(stderr, "%s: %s: %s\n", argv[0], err_msg, strerror(errno));

cleanup:
    if (mounts != NULL) {
        free(mounts);
    }
    if (envs != NULL) {
        free(envs);
    }
    if (setgroups_fd >= 0) {
        close(setgroups_fd);
    }
    if (uid_map_fd >= 0) {
        close(uid_map_fd);
    }
    if (gid_map_fd >= 0) {
        close(gid_map_fd);
    }

    return ok;
}
EOF
    cc -O2 -pipe -Wall -Wextra "$JINX_CACHE_DIR/rbrt.c" -o "$JINX_CACHE_DIR/rbrt"
}

reinit_container() {
    chmod -R 777 "$JINX_CACHE_DIR/sets" 2>/dev/null || true
    chmod -R 777 "$JINX_CACHE_DIR/apt-cache" 2>/dev/null || true
    rm -rf "$JINX_CACHE_DIR/debian-rootfs.tar.xz" "$JINX_CACHE_DIR/sets" "$JINX_CACHE_DIR/apt-cache"

    make_dir "${apt_cache}"

    curl -Lo "$JINX_CACHE_DIR/debian-rootfs.tar.xz" https://github.com/mintsuki/debian-rootfs/releases/download/${debian_snapshot}/debian-rootfs-${debian_architecture}.tar.xz
    if ! "$JINX_CACHE_DIR/b2sum" "$JINX_CACHE_DIR/debian-rootfs.tar.xz" | grep "${debian_rootfs_b2sum}" >/dev/null 2>&1; then
        die "Jinx: Failed to verify Debian rootfs tarball"
    fi
    ( cd "$JINX_CACHE_DIR" && xzcat debian-rootfs.tar.xz | tar -xf - )
    rm "$JINX_CACHE_DIR/debian-rootfs.tar.xz"
    make_dir "$JINX_CACHE_DIR/sets"
    mv "$JINX_CACHE_DIR/debian-rootfs-${debian_architecture}" "$JINX_CACHE_DIR/sets/.image"

    echo 'en_US.UTF-8 UTF-8' > "$JINX_CACHE_DIR/sets/.image/etc/locale.gen"
    echo 'APT::Install-Suggests "0";
APT::Install-Recommends "0";
APT::Sandbox::User "root";
Acquire::Check-Valid-Until "0";' >> "$JINX_CACHE_DIR/sets/.image/etc/apt/apt.conf"

    sources_list_tmp="$(sed 's/sid/experimental/g' "$JINX_CACHE_DIR/sets/.image/etc/apt/sources.list")"
    echo "${sources_list_tmp}" >>"$JINX_CACHE_DIR/sets/.image/etc/apt/sources.list"

    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get update
    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get install -y locales
    run_in_container1 "$JINX_CACHE_DIR/sets/.image" locale-gen

    # Fix permissions of files
    for f in $(find "$JINX_CACHE_DIR/sets/.image" -perm 000 2>/dev/null); do
        chmod 755 "$f"
    done

    run_in_container1 "$JINX_CACHE_DIR/sets/.image" apt-get install -y autopoint bash bison bzip2 cmake curl diffutils docbook-xsl doxygen file findutils flex gawk gettext git grep gzip lzip m4 make mercurial meson ninja-build patch perl python3 sed tar texinfo w3m which xmlto xsltproc xz-utils zstd

    # Build xbps
    XBPS_BUILDENV="$JINX_CACHE_DIR/xbps_buildenv"
    cp -Pprf "$JINX_CACHE_DIR/sets/.image/." "${XBPS_BUILDENV}/"
    curl -Lo "${XBPS_BUILDENV}/xbps-${XBPS_VERSION}.tar.gz" https://github.com/void-linux/xbps/archive/refs/tags/${XBPS_VERSION}.tar.gz
    if ! "$JINX_CACHE_DIR/b2sum" "${XBPS_BUILDENV}/xbps-${XBPS_VERSION}.tar.gz" | grep "${XBPS_B2SUM}" >/dev/null 2>&1; then
        die "Jinx: Failed to verify XBPS tarball"
    fi
    ( cd "${XBPS_BUILDENV}" && gunzip < xbps-${XBPS_VERSION}.tar.gz | tar -xf - )
    run_in_container1 "${XBPS_BUILDENV}" apt-get install -y build-essential pkg-config zlib1g-dev libssl-dev libarchive-dev
    # XXX: xbps upstream forgot to bump version string
    run_in_container1 "${XBPS_BUILDENV}" sed -i 's/0\.60/0.60.3/g' /xbps-${XBPS_VERSION}/configure
    run_in_container1 "${XBPS_BUILDENV}" sed -i 's/&& DEBUG=yes/&& DEBUG=no/g' /xbps-${XBPS_VERSION}/configure
    run_in_container1 "${XBPS_BUILDENV}" sh -c "cd /xbps-${XBPS_VERSION} && CFLAGS='-O2 -pipe -Wno-error' ./configure --verbose --enable-static --enable-rpath --prefix=/ --sysconfdir=/etc"
    run_in_container1 "${XBPS_BUILDENV}" sed -i 's/-lxml2/-lxml2 -llzma -lm/g' /xbps-${XBPS_VERSION}/config.mk
    run_in_container1 "${XBPS_BUILDENV}" sh -c "cd /xbps-${XBPS_VERSION} && make -j${parallelism} && make DESTDIR=/xbps-bin install"
    for f in "${XBPS_BUILDENV}"/xbps-bin/bin/*.static; do
        mv "$f" "${f%.static*}"
    done
    mv "${XBPS_BUILDENV}/xbps-bin/bin" "$JINX_CACHE_DIR/xbps-bin"

    cat >"${XBPS_BUILDENV}/nochown.c" <<EOF
#include <stdio.h>
#include <unistd.h>
#include <fcntl.h>

int chown(const char *pathname, uid_t owner, gid_t group) {
    if ((owner == 0 && group == 0)
     || (owner == $(id -u) && group == $(id -g))) {
        return 0;
    }
    printf("\e[93mchown(%s, %d, %d); suppressed\e[0m\n", pathname, owner, group);
    return 0;
}

int fchown(int fd, uid_t owner, gid_t group) {
    if ((owner == 0 && group == 0)
     || (owner == $(id -u) && group == $(id -g))) {
        return 0;
    }
    printf("\e[93mfchown(%d, %d, %d); suppressed\e[0m\n", fd, owner, group);
    return 0;
}

int lchown(const char *pathname, uid_t owner, gid_t group) {
    if ((owner == 0 && group == 0)
     || (owner == $(id -u) && group == $(id -g))) {
        return 0;
    }
    printf("\e[93mlchown(%s, %d, %d); suppressed\e[0m\n", pathname, owner, group);
    return 0;
}

int fchownat(int dirfd, const char *pathname,
             uid_t owner, gid_t group, int flags) {
    if ((owner == 0 && group == 0)
     || (owner == $(id -u) && group == $(id -g))) {
        return 0;
    }
    printf("\e[93mfchownat(%d, %s, %d, %d, %d); suppressed\e[0m\n", dirfd, pathname, owner, group, flags);
    return 0;
}
EOF
    run_in_container1 "${XBPS_BUILDENV}" gcc -O2 -pipe -Wall -Wextra -fPIC -shared /nochown.c -o /nochown.so
    mv "${XBPS_BUILDENV}/nochown."* "$JINX_CACHE_DIR/"

    chmod -R 777 "${XBPS_BUILDENV}"
    rm -rf "${XBPS_BUILDENV}"
}

first_use() {
    echo "* preparing Jinx cache..."

    make_dir "$JINX_CACHE_DIR"

    rebuild_b2sum
    rebuild_rbrt

    reinit_container

    echo "$jinx_version" > "$JINX_CACHE_DIR/version"

    echo "* done"
}

redo_first_use() {
    echo "* purging old Jinx cache..."
    chmod -R 777 "$JINX_CACHE_DIR" || true
    rm -rf "$JINX_CACHE_DIR"
    first_use
}

if ! [ -f "$JINX_CONFIG_FILE" ]; then
    die "$0: missing Jinxfile in directory '$base_dir'"
fi

. "${JINX_CONFIG_FILE}"

if [ -z "$JINX_MAJOR_VER" ]; then
    die "$0: required config variable \$JINX_MAJOR_VER missing"
fi

if ! [ "$JINX_MAJOR_VER" = "$jinx_major_ver" ]; then
    die "$0: needed major version ($JINX_MAJOR_VER) differs from Jinx-provided major version ($jinx_major_ver)"
fi

if [ -z "$JINX_ARCH" ]; then
    die "$0: required config variable \$JINX_ARCH missing"
fi

if ! [ -d "$JINX_CACHE_DIR" ]; then
    first_use
fi

if ! [ -f "$JINX_CACHE_DIR/version" ] || ! [ "$(cat "$JINX_CACHE_DIR/version")" = "$jinx_version" ]; then
    redo_first_use
fi

case "$1" in
    internal-prepare)
        do_prepare "$2"
        ;;
    internal-precont-fetch)
        precont_fetch "$2"
        ;;
    internal-cont-fetch)
        cont_fetch "$2"
        ;;
    internal-precont-patch)
        precont_patch "$2"
        ;;
    internal-cont-patch)
        cont_patch "$2"
        ;;
    internal-configure-host)
        do_configure_host "$2"
        ;;
    internal-build-host)
        do_build_host "$2"
        ;;
    internal-package-host)
        do_package_host "$2"
        ;;
    internal-configure)
        do_configure "$2"
        ;;
    internal-build)
        do_build "$2"
        ;;
    internal-package)
        do_package "$2"
        ;;
    internal-get-deps-file)
        . "${base_dir}"/recipes/$2
        deps_file="$3"
        get_deps_file
        ;;
    internal-get-hostdeps-file-run)
        . "${base_dir}"/host-recipes/$2
        hostdeps_file="$3"
        get_hostdeps_file_run
        ;;
    internal-source)
        do_source "$2"
        ;;
    internal-do-host-pkg)
        do_host_pkg "$2"
        ;;
    internal-do-pkg)
        do_pkg "$2"
        ;;
    internal-do-prepare)
        do_cmd_prepare "$2"
        ;;
    internal-do-host-rebuild)
        do_cmd_host_rebuild "$2"
        ;;
    internal-do-rebuild)
        do_cmd_rebuild "$2"
        ;;
    host-build)
        shift 1
        cmd_host_build "$@"
        ;;
    build)
        shift 1
        cmd_build "$@"
        ;;
    build-if-needed)
        shift 1
        cmd_build_if_needed "$@"
        ;;
    regenerate|regen)
        shift 1
        cmd_prepare "$@"
        ;;
    host-rebuild)
        shift 1
        cmd_host_rebuild "$@"
        ;;
    rebuild)
        shift 1
        cmd_rebuild "$@"
        ;;
    install)
        shift 1
        cmd_install "$@"
        ;;
    reinstall)
        shift 1
        cmd_install -f "$@"
        ;;
    rbrt)
        rebuild_rbrt
        ;;
    rebuild-cache)
        redo_first_use
        ;;
    *)
        die "$0: unknown command: $1"
        ;;
esac
